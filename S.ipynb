{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13686f50",
   "metadata": {},
   "source": [
    "Mohammadreza Jamalifard - 2022 (C) All rights reserved\n",
    "I would like to acknolweldege the authors of [Norm-Explicit Quantization: Improving Vector\n",
    "Quantization for Maximum Inner Product Search] [2020], from where parts of their source code was recycled for this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aac8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from scipy.stats import ortho_group\n",
    "import numba as nb\n",
    "from scipy.cluster.vq import kmeans2, vq\n",
    "import warnings\n",
    "import math\n",
    "import tqdm\n",
    "from fcmeans import FCM\n",
    "from multiprocessing import cpu_count\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "3488e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit\n",
    "def arg_sort(distances):\n",
    "    top_k = min(131072, len(distances)-1)\n",
    "    indices = np.argpartition(distances, top_k)[:top_k]\n",
    "    return indices[np.argsort(distances[indices])]\n",
    "\n",
    "\n",
    "@nb.jit\n",
    "def product_arg_sort(q, compressed):\n",
    "    distances = np.dot(compressed, -q)\n",
    "    return arg_sort(distances)\n",
    "\n",
    "\n",
    "@nb.jit\n",
    "def angular_arg_sort(q, compressed, norms_sqr):\n",
    "    norm_q = np.linalg.norm(q)\n",
    "    distances = np.dot(compressed, q) / (norm_q * norms_sqr)\n",
    "    return arg_sort(distances)\n",
    "\n",
    "\n",
    "@nb.jit\n",
    "def euclidean_arg_sort(q, compressed):\n",
    "    distances = np.linalg.norm(q - compressed, axis=1)\n",
    "    return arg_sort(distances)\n",
    "\n",
    "\n",
    "@nb.jit\n",
    "def sign_arg_sort(q, compressed):\n",
    "    distances = np.empty(len(compressed), dtype=np.int32)\n",
    "    for i in range(len(compressed)):\n",
    "        distances[i] = np.count_nonzero((q > 0) != (compressed[i] > 0))\n",
    "    return arg_sort(distances)\n",
    "\n",
    "\n",
    "@nb.jit\n",
    "def euclidean_norm_arg_sort(q, compressed, norms_sqr):\n",
    "    distances = norms_sqr - 2.0 * np.dot(compressed, q)\n",
    "    return arg_sort(distances)\n",
    "\n",
    "\n",
    "@nb.jit\n",
    "def parallel_sort(metric, compressed, Q, X, norms_sqr=None):\n",
    "    \"\"\"\n",
    "    for each q in 'Q', sort the compressed items in 'compressed' by their distance,\n",
    "    where distance is determined by 'metric'\n",
    "    :param metric: euclid product\n",
    "    :param compressed: compressed items, same dimension as origin data, shape(N * D)\n",
    "    :param Q: queries, shape(len(Q) * D)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    rank = np.empty((Q.shape[0], min(131072, compressed.shape[0]-1)), dtype=np.int32)\n",
    "\n",
    "    p_range = tqdm.tqdm(nb.prange(Q.shape[0]))\n",
    "\n",
    "    if metric == 'product':\n",
    "        for i in p_range:\n",
    "            rank[i, :] = product_arg_sort(Q[i], compressed)\n",
    "    elif metric == 'angular':\n",
    "        if norms_sqr is None:\n",
    "            norms_sqr = np.linalg.norm(compressed, axis=1) ** 2\n",
    "        for i in p_range:\n",
    "            rank[i, :] = angular_arg_sort(Q[i], compressed, norms_sqr)\n",
    "    elif metric == 'euclid_norm':\n",
    "        if norms_sqr is None:\n",
    "            norms_sqr = np.linalg.norm(compressed, axis=1) ** 2\n",
    "        for i in p_range:\n",
    "            rank[i, :] = euclidean_norm_arg_sort(Q[i], compressed, norms_sqr)\n",
    "    else:\n",
    "        for i in p_range:\n",
    "            rank[i, :] = euclidean_arg_sort(Q[i], compressed)\n",
    "\n",
    "    return rank\n",
    "\n",
    "\n",
    "@nb.jit\n",
    "def true_positives(topK, Q, G, T):\n",
    "    result = np.empty(shape=(len(Q)))\n",
    "    for i in nb.prange(len(Q)):\n",
    "        result[i] = len(np.intersect1d(G[i], topK[i][:T]))\n",
    "    return result\n",
    "\n",
    "\n",
    "class Sorter(object):\n",
    "    def __init__(self, compressed, Q, X, metric, norms_sqr=None):\n",
    "        self.Q = Q\n",
    "        self.X = X\n",
    "\n",
    "        self.topK = parallel_sort(metric, compressed, Q, X, norms_sqr=norms_sqr)\n",
    "\n",
    "    def recall(self, G, T):\n",
    "        t = min(T, len(self.topK[0]))\n",
    "        return t, self.sum_recall(G, T) / len(self.Q)\n",
    "\n",
    "    def sum_recall(self, G, T):\n",
    "        assert len(self.Q) == len(self.topK), \"number of query not equals\"\n",
    "        assert len(self.topK) <= len(G), \"number of queries should not exceed the number of queries in ground truth\"\n",
    "        true_positive = true_positives(self.topK, self.Q, G, T)\n",
    "        return np.sum(true_positive) / len(G[0])  # TP / K\n",
    "\n",
    "\n",
    "class BatchSorter(object):\n",
    "    def __init__(self, compressed, Q, X, G, Ts, metric, batch_size, norms_sqr=None):\n",
    "        self.Q = Q\n",
    "        self.X = X\n",
    "        self.recalls = np.zeros(shape=(len(Ts)))\n",
    "        for i in range(math.ceil(len(Q) / float(batch_size))):\n",
    "            q = Q[i*batch_size: (i + 1) * batch_size, :]\n",
    "            g = G[i*batch_size: (i + 1) * batch_size, :]\n",
    "            sorter = Sorter(compressed, q, X, metric=metric, norms_sqr=norms_sqr)\n",
    "            self.recalls[:] = self.recalls[:] + [sorter.sum_recall(g, t) for t in Ts]\n",
    "        self.recalls = self.recalls / len(self.Q)\n",
    "\n",
    "    def recall(self):\n",
    "        return self.recalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0fe04158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PQ(object):\n",
    "    def __init__(self, M, Ks, verbose=True):\n",
    "        assert 0 < Ks <= 2 ** 32\n",
    "        self.M, self.Ks, self.verbose = M, Ks, verbose\n",
    "        self.code_dtype = np.uint8 if Ks <= 2 ** 8 else (np.uint16 if Ks <= 2 ** 16 else np.uint32)\n",
    "        self.codewords = None\n",
    "        self.Ds = None\n",
    "        self.Dim = -1\n",
    "\n",
    "    def class_message(self):\n",
    "        return \"Subspace PQ, M: {}, Ks : {}, code_dtype: {}\".format(self.M, self.Ks, self.code_dtype)\n",
    "\n",
    "    def fit(self, vecs, iter):\n",
    "        assert vecs.dtype == np.float32\n",
    "        assert vecs.ndim == 2\n",
    "        N, D = vecs.shape\n",
    "        assert self.Ks < N, \"the number of training vector should be more than Ks\"\n",
    "        self.Dim = D\n",
    "\n",
    "        reminder = D % self.M\n",
    "        quotient = int(D / self.M)\n",
    "        dims_width = [quotient + 1 if i < reminder else quotient for i in range(self.M)]\n",
    "        self.Ds = np.cumsum(dims_width)     # prefix sum\n",
    "        self.Ds = np.insert(self.Ds, 0, 0)  # insert zero at beginning\n",
    "\n",
    "        # [m][ks][ds]: m-th subspace, ks-the codeword, ds-th dim\n",
    "        self.codewords = np.zeros((self.M, self.Ks, np.max(dims_width)), dtype=np.float32)\n",
    "        for m in range(self.M):\n",
    "            if self.verbose:\n",
    "                print(\"#    Training the subspace: {} / {}, {} -> {}\".format(m, self.M, self.Ds[m], self.Ds[m+1]))\n",
    "            vecs_sub = vecs[:, self.Ds[m]:self.Ds[m+1]]\n",
    "            self.codewords[m, :, :self.Ds[m+1] - self.Ds[m]], _ = kmeans2(\n",
    "                vecs_sub, self.Ks, iter=iter, minit='points')\n",
    "\n",
    "        return self\n",
    "\n",
    "    def encode(self, vecs):\n",
    "        assert vecs.dtype == np.float32\n",
    "        assert vecs.ndim == 2\n",
    "        N, D = vecs.shape\n",
    "\n",
    "        # codes[n][m] : code of n-th vec, m-th subspace\n",
    "        codes = np.empty((N, self.M), dtype=self.code_dtype)\n",
    "        for m in range(self.M):\n",
    "            vecs_sub = vecs[:, self.Ds[m]: self.Ds[m+1]]\n",
    "            codes[:, m], _ = vq(vecs_sub,\n",
    "                                self.codewords[m, :, :self.Ds[m+1] - self.Ds[m]])\n",
    "\n",
    "        return codes\n",
    "\n",
    "    def decode(self, codes):\n",
    "        assert codes.ndim == 2\n",
    "        N, M = codes.shape\n",
    "        assert M == self.M\n",
    "        assert codes.dtype == self.code_dtype\n",
    "\n",
    "        vecs = np.empty((N, self.Dim), dtype=np.float32)\n",
    "        for m in range(self.M):\n",
    "            vecs[:, self.Ds[m]: self.Ds[m+1]] = self.codewords[m, codes[:, m], :self.Ds[m+1] - self.Ds[m]]\n",
    "\n",
    "        return vecs\n",
    "\n",
    "    def compress(self, vecs):\n",
    "        return self.decode(self.encode(vecs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "bb963109",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PQ(object):\n",
    "    def __init__(self, M, Ks, verbose=True):\n",
    "        assert 0 < Ks <= 2 ** 32\n",
    "        self.M, self.Ks, self.verbose = M, Ks, verbose\n",
    "        self.code_dtype = np.uint8 if Ks <= 2 ** 8 else (np.uint16 if Ks <= 2 ** 16 else np.uint32)\n",
    "        self.codewords = None\n",
    "        self.Ds = None\n",
    "        self.Dim = -1\n",
    "\n",
    "    def class_message(self):\n",
    "        return \"Subspace PQ, M: {}, Ks : {}, code_dtype: {}\".format(self.M, self.Ks, self.code_dtype)\n",
    "\n",
    "    def fit(self, vecs, iter):\n",
    "        assert vecs.dtype == np.float32\n",
    "        assert vecs.ndim == 2\n",
    "        N, D = vecs.shape\n",
    "        assert self.Ks < N, \"the number of training vector should be more than Ks\"\n",
    "        self.Dim = D\n",
    "\n",
    "        reminder = D % self.M\n",
    "        quotient = int(D / self.M)\n",
    "        dims_width = [quotient + 1 if i < reminder else quotient for i in range(self.M)]\n",
    "        self.Ds = np.cumsum(dims_width)     # prefix sum\n",
    "        self.Ds = np.insert(self.Ds, 0, 0)  # insert zero at beginning\n",
    "\n",
    "        # [m][ks][ds]: m-th subspace, ks-the codeword, ds-th dim\n",
    "        self.codewords = np.zeros((self.M, self.Ks, np.max(dims_width)), dtype=np.float32)\n",
    "        for m in range(self.M):\n",
    "            if self.verbose:\n",
    "                print(\"#    Training the subspace: {} / {}, {} -> {}\".format(m, self.M, self.Ds[m], self.Ds[m+1]))\n",
    "            vecs_sub = vecs[:, self.Ds[m]:self.Ds[m+1]]\n",
    "            self.codewords[m, :, :self.Ds[m+1] - self.Ds[m]], _ = kmeans2(\n",
    "                vecs_sub, self.Ks, iter=iter, minit='points')\n",
    "\n",
    "        return self\n",
    "\n",
    "    def encode(self, vecs):\n",
    "        assert vecs.dtype == np.float32\n",
    "        assert vecs.ndim == 2\n",
    "        N, D = vecs.shape\n",
    "\n",
    "        # codes[n][m] : code of n-th vec, m-th subspace\n",
    "        codes = np.empty((N, self.M), dtype=self.code_dtype)\n",
    "        for m in range(self.M):\n",
    "            vecs_sub = vecs[:, self.Ds[m]: self.Ds[m+1]]\n",
    "            codes[:, m], _ = vq(vecs_sub,\n",
    "                                self.codewords[m, :, :self.Ds[m+1] - self.Ds[m]])\n",
    "\n",
    "        return codes\n",
    "\n",
    "    def decode(self, codes):\n",
    "        assert codes.ndim == 2\n",
    "        N, M = codes.shape\n",
    "        assert M == self.M\n",
    "        assert codes.dtype == self.code_dtype\n",
    "\n",
    "        vecs = np.empty((N, self.Dim), dtype=np.float32)\n",
    "        for m in range(self.M):\n",
    "            vecs[:, self.Ds[m]: self.Ds[m+1]] = self.codewords[m, codes[:, m], :self.Ds[m+1] - self.Ds[m]]\n",
    "\n",
    "        return vecs\n",
    "\n",
    "    def compress(self, vecs):\n",
    "        return self.decode(self.encode(vecs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "fdff04cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize(vecs):\n",
    "    norms = np.linalg.norm(vecs, axis=1)\n",
    "    norms_matrix = norms[:, np.newaxis]\n",
    "    normalized_vecs = np.divide(vecs, norms_matrix, out=np.zeros_like(vecs), where=norms_matrix != 0)  # divide by zero problem\n",
    "    return norms, normalized_vecs\n",
    "\n",
    "\n",
    "def zero_mean(X, Q):\n",
    "    mean = X.mean(axis=0, keepdims=True)\n",
    "    X = X - mean\n",
    "    Q = Q - mean\n",
    "    return X, Q\n",
    "\n",
    "\n",
    "def random_rotate(X, Q):\n",
    "    R = ortho_group.rvs(dim=len(X[0]))\n",
    "    R = np.array(R, dtype=np.float32)\n",
    "    X = R.dot(X.transpose()).transpose()\n",
    "    Q = R.dot(Q.transpose()).transpose()\n",
    "    return X, Q\n",
    "\n",
    "\n",
    "def scale(X, Q):\n",
    "    scale = np.max(np.linalg.norm(X, axis=1))\n",
    "    X /= scale\n",
    "    Q /= scale\n",
    "    return X, Q\n",
    "\n",
    "\n",
    "def one_half_coeff_scale(X, Q):\n",
    "    mean = np.mean(np.absolute(X))\n",
    "    X /= (mean * 2);\n",
    "    Q /= (mean * 2);\n",
    "    return X, Q\n",
    "\n",
    "def coeff_scale(X, Q, scale):\n",
    "    mean = np.mean(np.absolute(X))\n",
    "    X /= (mean / scale);\n",
    "    Q /= (mean / scale);\n",
    "    return X, Q\n",
    "\n",
    "def inverse_d_coeff_scale(X, Q):\n",
    "    mean = np.mean(np.absolute(X))\n",
    "    X /= (mean * X.shape[1]);\n",
    "    Q /= (mean * X.shape[1])\n",
    "    return X, Q\n",
    "\n",
    "@nb.jit(nopython=True)\n",
    "def norm_range(norm_sqrs, num_intervals):\n",
    "    num_intervals_minus_1 = float(num_intervals - 1)\n",
    "\n",
    "    norm_sqr_max = np.amax(norm_sqrs)\n",
    "    norm_sqr_min = np.amin(norm_sqrs)\n",
    "\n",
    "    means = np.empty((norm_sqrs.shape[0]), dtype=np.float32)\n",
    "\n",
    "    for i in range(norm_sqrs.shape[0]):\n",
    "        bucket = int((norm_sqrs[i] - norm_sqr_min) / (norm_sqr_max - norm_sqr_min) * num_intervals_minus_1)\n",
    "        left = bucket / num_intervals_minus_1 * (norm_sqr_max - norm_sqr_min) + norm_sqr_min\n",
    "        right = (bucket + 1) / num_intervals_minus_1 * (norm_sqr_max - norm_sqr_min) + norm_sqr_min\n",
    "        mean = (left + right) / 2.0\n",
    "\n",
    "        means[i] = mean\n",
    "\n",
    "    return means\n",
    "\n",
    "def norm_range_non_uniform(norm_sqrs):\n",
    "    code_book, code = kmeans2(norm_sqrs[:, np.newaxis], 256, iter=20, minit='points')\n",
    "    return code_book[code, 0]\n",
    "\n",
    "def e2m_transform(X, Q):\n",
    "    M = np.max(np.linalg.norm(X, axis=1))\n",
    "    X_plus = np.zeros((len(X), 4), dtype=np.float32)\n",
    "    Q_plus = np.zeros((len(Q), 4), dtype=np.float32)\n",
    "\n",
    "    X_plus[:, 0] = M - np.linalg.norm(X, axis=1) ** 2\n",
    "    Q_plus[:, 0] = 0.5\n",
    "    X = np.append(X, X_plus, axis=1)\n",
    "    Q = np.append(Q, Q_plus, axis=1)\n",
    "    return X, Q\n",
    "\n",
    "\n",
    "def e2m_mahalanobis(X):\n",
    "    X_plus = np.full((len(X), 1), fill_value=-0.5, dtype=np.float32)\n",
    "    X = np.append(X, X_plus, axis=1)\n",
    "    return np.dot(X.transpose(), X) / float(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "48d103ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormPQ(object):\n",
    "    def __init__(self, n_percentile, quantize, true_norm=False, verbose=True, method='kmeans', recover='quantize'):\n",
    "\n",
    "        self.M = 2\n",
    "        self.n_percentile, self.true_norm, self.verbose = n_percentile, true_norm, verbose\n",
    "        self.method = method\n",
    "        self.recover = recover\n",
    "        self.code_dtype = np.uint8 if n_percentile <= 2 ** 8 \\\n",
    "            else (np.uint16 if n_percentile <= 2 ** 16 else np.uint32)\n",
    "\n",
    "        self.percentiles = None\n",
    "        self.quantize = quantize\n",
    "\n",
    "    def class_message(self):\n",
    "        return \"NormPQ, percentiles: {}, quantize: {}\".format(self.n_percentile, self.quantize.class_message())\n",
    "\n",
    "    def fit(self, vecs, iter):\n",
    "        assert vecs.dtype == np.float32\n",
    "        assert vecs.ndim == 2\n",
    "        N, D = vecs.shape\n",
    "        assert self.n_percentile < N, \"the number of norm intervals should be more than Ks\"\n",
    "\n",
    "        norms, normalized_vecs = normalize(vecs)\n",
    "        self.quantize.fit(normalized_vecs, iter)\n",
    "\n",
    "        if self.recover == 'quantize':\n",
    "            compressed_vecs = self.quantize.compress(normalized_vecs)\n",
    "            norms = norms / np.linalg.norm(compressed_vecs, axis=1)\n",
    "            \n",
    "        elif self.recover == 'normalization':\n",
    "            warnings.warn(\"Recover norm by normalization.\")\n",
    "            assert False\n",
    "        else:\n",
    "            warnings.warn(\"No normalization guarantee.\")\n",
    "            assert False\n",
    "\n",
    "        if self.method == 'kmeans':\n",
    "            print(norms)\n",
    "            self.percentiles, _ = kmeans2(norms[:], self.n_percentile, iter=iter, minit='points')\n",
    "        elif self.method == 'kmeans_partial':\n",
    "            indexes = np.argsort(norms)\n",
    "            count = int(len(norms) * 0.7)\n",
    "            centers_small_norms, _ = kmeans2(norms[indexes[:count]], self.n_percentile // 2, iter=iter, minit='points')\n",
    "            centers_big_norms, _ = kmeans2(norms[indexes[count:]], self.n_percentile // 2, iter=iter, minit='points')\n",
    "            self.percentiles = np.concatenate((centers_small_norms, centers_big_norms))\n",
    "\n",
    "        elif self.method == 'percentile':\n",
    "            self.percentiles = np.percentile(norms, np.linspace(0, 100, self.n_percentile + 1)[:])\n",
    "            self.percentiles = np.array(self.percentiles, dtype=np.float32)\n",
    "        elif self.method == 'fcm':\n",
    "            normv2 = np.reshape(norms, (-1, 2))\n",
    "            fcm_model = FCM(n_clusters = self.n_percentile, max_iter = iter)\n",
    "            fcm_model.fit(normv2)\n",
    "            self.percentiles = (fcm_model.centers[:,0] + fcm_model.centers[:,1])/2\n",
    "            np.savetxt('centers.txt',fcm_model.centers)\n",
    "            np.savetxt(\"file.txt\",self.percentiles)\n",
    "        elif self.method == 'exponential':\n",
    "            q = 0.98\n",
    "            a = (1 - q) / (1 - q**self.n_percentile)  # make sure that sum of a*q**i is 1\n",
    "            self.percentiles = [\n",
    "                np.min(norms) if i == 0 else\n",
    "                np.min(norms) + a * (1 - q**i) / (1 - q) * (np.max(norms) - np.min(norms))\n",
    "                for i in range(self.n_percentile + 1)\n",
    "            ]\n",
    "\n",
    "            self.percentiles = np.array(self.percentiles, dtype=np.float32)\n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def encode_norm(self, norms):\n",
    "\n",
    "        if self.method == 'kmeans' or self.method == 'kmeans_partial':\n",
    "            norm_index, _ = vq(norms[:], self.percentiles)\n",
    "        else:\n",
    "            norm_index = [np.argmax(self.percentiles[1:] > n) for n in norms]\n",
    "            norm_index = np.clip(norm_index, 1, self.n_percentile)\n",
    "        return norm_index\n",
    "\n",
    "    def decode_norm(self, norm_index):\n",
    "        if self.method == 'kmeans' or self.method == 'kmeans_partial' or self.method=='fcm':\n",
    "            return self.percentiles[norm_index]\n",
    "        else:\n",
    "            return (self.percentiles[norm_index]+self.percentiles[norm_index-1]) / 2.0\n",
    "\n",
    "    def compress(self, vecs):\n",
    "        norms, normalized_vecs = normalize(vecs)\n",
    "\n",
    "        compressed_vecs = self.quantize.compress(normalized_vecs)\n",
    "        del normalized_vecs\n",
    "\n",
    "        if self.recover == 'quantize':\n",
    "            norms = norms / np.linalg.norm(compressed_vecs, axis=1)\n",
    "        elif self.recover == 'normalization':\n",
    "            warnings.warn(\"Recover norm by normalization.\")\n",
    "            _, compressed_vecs = normalize(compressed_vecs)\n",
    "            assert False\n",
    "        else:\n",
    "            warnings.warn(\"No normalization guarantee.\")\n",
    "            assert False\n",
    "\n",
    "        if not self.true_norm:\n",
    "            norms = self.decode_norm(self.encode_norm(norms))\n",
    "        else:\n",
    "            warnings.warn(\"Using true norm to compress vector.\")\n",
    "            assert False\n",
    "\n",
    "        return (compressed_vecs.transpose() * norms).transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "f2a22da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualPQ(object):\n",
    "    def __init__(self, pqs=None, verbose=True):\n",
    "\n",
    "        assert len(pqs) > 0\n",
    "        self.verbose = verbose\n",
    "        self.deep = len(pqs)\n",
    "        self.code_dtype = pqs[0].code_dtype\n",
    "        self.M = max([pq.M for pq in pqs])\n",
    "        self.pqs = pqs\n",
    "\n",
    "        for pq in self.pqs:\n",
    "            assert pq.code_dtype == self.code_dtype\n",
    "\n",
    "    def class_message(self):\n",
    "        messages = \"\"\n",
    "        for i, pq in enumerate(self.pqs):\n",
    "            messages += pq.class_message()\n",
    "        return messages\n",
    "\n",
    "    def fit(self, T, iter, save_codebook=False, save_decoded=[], save_residue_norms=[], save_results_T=False, dataset_name=None, save_dir=None, D=None):\n",
    "        assert T.dtype == np.float32\n",
    "        assert T.ndim == 2\n",
    "\n",
    "        if save_dir is None:\n",
    "            save_dir = './results'\n",
    "\n",
    "        vecs = np.empty(shape=T.shape, dtype=T.dtype)\n",
    "        vecs[:, :] = T[:, :]\n",
    "        if D is not None:\n",
    "            vecs_d = np.empty(shape=D.shape, dtype=D.dtype)\n",
    "            vecs_d[:, :] = D[:, :]\n",
    "        if save_codebook:\n",
    "            codebook_f = open(save_dir + '/' + dataset_name + '_rq_' + str(self.deep) + '_' + str(self.pqs[0].Ks) + '_codebook', 'wb')\n",
    "\n",
    "        for layer, pq in enumerate(self.pqs):\n",
    "            pq.fit(vecs, iter)\n",
    "            compressed = pq.compress(vecs)\n",
    "            vecs = vecs - compressed\n",
    "            del compressed\n",
    "\n",
    "            if D is not None:\n",
    "                compressed_d = pq.compress(vecs_d)\n",
    "                vecs_d -= compressed_d\n",
    "\n",
    "            if self.verbose:\n",
    "                norms = np.linalg.norm(vecs, axis=1)\n",
    "                print(\"# layer: {},  residual average norm : {} max norm: {} min norm: {}\"\n",
    "                      .format(layer, np.mean(norms), np.max(norms), np.min(norms)))\n",
    "\n",
    "            if (layer + 1) in save_residue_norms:\n",
    "                with open(save_dir + '/' + dataset_name + '_rq_' + str(layer + 1) + '_' + str(self.pqs[0].Ks) + '_residue_norms', 'wb') as f:\n",
    "                    if save_results_T:\n",
    "                        np.linalg.norm(vecs, axis=1).tofile(f)\n",
    "                    if D is not None:\n",
    "                        np.linalg.norm(vecs_d, axis=1).tofile(f)\n",
    "\n",
    "            if (layer + 1) in save_decoded:\n",
    "                with open(save_dir + '/' + dataset_name + '_rq_' + str(layer + 1) + '_' + str(self.pqs[0].Ks) + '_decoded', 'wb') as f:\n",
    "                    if save_results_T:\n",
    "                        (T - vecs).tofile(f)\n",
    "                    if D is not None:\n",
    "                        (D - vecs_d).tofile(f)\n",
    "\n",
    "            if save_codebook:\n",
    "                pq.codewords.tofile(codebook_f)\n",
    "                codebook_f.flush()\n",
    "\n",
    "        if save_codebook:\n",
    "            codebook_f.close()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def encode(self, vecs):\n",
    "        \"\"\"\n",
    "        :param vecs:\n",
    "        :return: (N * deep * M)\n",
    "        \"\"\"\n",
    "        codes = np.zeros((len(vecs), self.deep, self.M), dtype=self.code_dtype)  # N * deep * M\n",
    "        for i, pq in enumerate(self.pqs):\n",
    "            codes[:, i, :pq.M] = pq.encode(vecs)\n",
    "            vecs = vecs - pq.decode(codes[:, i, :pq.M])\n",
    "        return codes  # N * deep * M\n",
    "\n",
    "    def decode(self, codes):\n",
    "        vecss = [pq.decode(codes[:, i, :pq.M]) for i, pq in enumerate(self.pqs)]\n",
    "        return np.sum(vecss, axis=0)\n",
    "\n",
    "    def compress(self, X):\n",
    "        N, D = np.shape(X)\n",
    "\n",
    "        sum_residual = np.zeros((N, D), dtype=X.dtype)\n",
    "\n",
    "        vecs = np.zeros((N, D), dtype=X.dtype)\n",
    "        vecs[:, :] = X[:, :]\n",
    "\n",
    "        for i, pq in enumerate(self.pqs):\n",
    "            compressed = pq.compress(vecs)\n",
    "            vecs[:, :] = vecs - compressed\n",
    "            sum_residual[:, :] = sum_residual + compressed\n",
    "            del compressed\n",
    "\n",
    "        return sum_residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "fe4a0cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ivecs_read(fname):\n",
    "    a = np.fromfile(fname, dtype='int32')\n",
    "    d = a[0]\n",
    "    return a.reshape(-1, d + 1)[:, 1:].copy()\n",
    "\n",
    "\n",
    "def fvecs_read(fname):\n",
    "    return ivecs_read(fname).view('float32')\n",
    "\n",
    "\n",
    "def bvecs_read(fname):\n",
    "    a = np.fromfile(fname, dtype='uint8')\n",
    "    d = a[:4].view('uint8')[0]\n",
    "    return a.reshape(-1, d + 4)[:, 4:].copy()\n",
    "\n",
    "\n",
    "# we mem-map the biggest files to avoid having them in memory all at\n",
    "# once\n",
    "def mmap_fvecs(fname):\n",
    "    x = np.memmap(fname, dtype='int32', mode='r')\n",
    "    d = x[0]\n",
    "    return x.view('float32').reshape(-1, d + 1)[:, 1:]\n",
    "\n",
    "\n",
    "def mmap_bvecs(fname):\n",
    "    x = np.memmap(fname, dtype='uint8', mode='r')\n",
    "    d = x[:4].view('int32')[0]\n",
    "    return x.reshape(-1, d + 4)[:, 4:]\n",
    "\n",
    "\n",
    "def bvecs_read(filename):\n",
    "    return mmap_bvecs(fname=filename)\n",
    "\n",
    "\n",
    "def fvecs_writer(filename, vecs):\n",
    "    f = open(filename, \"ab\")\n",
    "    dimension = [len(vecs[0])]\n",
    "\n",
    "    for x in vecs:\n",
    "        f.write(struct.pack('i' * len(dimension), *dimension))\n",
    "        f.write(struct.pack('f' * len(x), *x))\n",
    "\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def ivecs_writer(filename, vecs):\n",
    "    f = open(filename, \"ab\")\n",
    "    dimension = [len(vecs[0])]\n",
    "\n",
    "    for x in vecs:\n",
    "        f.write(struct.pack('i' * len(dimension), *dimension))\n",
    "        f.write(struct.pack('i' * len(x), *x))\n",
    "\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def loader(data_set='audio', top_k=20, ground_metric='euclid', folder='../data/', data_type='fvecs'):\n",
    "    \"\"\"\n",
    "    :param data_set: data set you wanna load , audio, sift1m, ..\n",
    "    :param top_k: how many nearest neighbor in ground truth file\n",
    "    :param ground_metric:\n",
    "    :param folder:\n",
    "    :return: X, T, Q, G\n",
    "    \"\"\"\n",
    "    folder_path = folder + data_set\n",
    "    base_file = folder_path + '/%s_base.%s' % (data_set, data_type)\n",
    "    train_file = folder_path + '/%s_learn.%s' % (data_set, data_type)\n",
    "    query_file = folder_path + '/%s_query.%s' % (data_set, data_type)\n",
    "    ground_truth = folder_path + '/%s_%s_%s_groundtruth.ivecs' % \\\n",
    "                   (top_k, data_set, ground_metric)\n",
    "\n",
    "    print(\"# load the base data {}, \\n# load the queries {}, \\n# load the ground truth {}\".format(base_file, query_file,\n",
    "                                                                                            ground_truth))\n",
    "    if data_type == 'fvecs':\n",
    "        X = fvecs_read(base_file)\n",
    "        Q = fvecs_read(query_file)\n",
    "        try:\n",
    "            T = fvecs_read(train_file)\n",
    "        except FileNotFoundError:\n",
    "            T = None\n",
    "    elif data_type == 'bvecs':\n",
    "        X = bvecs_read(base_file).astype(np.float32)\n",
    "        Q = bvecs_read(query_file).astype(np.float32)\n",
    "        try:\n",
    "            T = bvecs_read(train_file)\n",
    "        except FileNotFoundError:\n",
    "            T = None\n",
    "    else:\n",
    "        assert False\n",
    "    try:\n",
    "        G = ivecs_read(ground_truth)\n",
    "    except FileNotFoundError:\n",
    "        G = None\n",
    "    return X, T, Q, G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad1de86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "6e78e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_compress(pq, vecs):\n",
    "    chunk_size = 11700\n",
    "    compressed_vecs = np.empty(shape=vecs.shape, dtype=np.float32)\n",
    "    for i in tqdm.tqdm(range(math.ceil(len(vecs) / chunk_size))):\n",
    "        compressed_vecs[i * chunk_size: (i + 1) * chunk_size, :] \\\n",
    "            = pq.compress(vecs[i * chunk_size: (i + 1) * chunk_size, :].astype(dtype=np.float32))\n",
    "    return compressed_vecs\n",
    "\n",
    "\n",
    "def execute(pq, X, T, Q, G, metric, train_size=11700):\n",
    "    np.random.seed(123)\n",
    "    np.random.shuffle(X)\n",
    "    print(\"# ranking metric {}\".format(metric))\n",
    "    print(\"# \"+pq.class_message())\n",
    "    if T is None:\n",
    "        pq.fit(X[:train_size].astype(dtype=np.float32), iter=20)\n",
    "    else:\n",
    "        pq.fit(T.astype(dtype=np.float32), iter=20)\n",
    "\n",
    "    print('# compress items')\n",
    "    compressed = chunk_compress(pq, X)\n",
    "    print(\"# sorting items\")\n",
    "    Ts = [2 ** i for i in range(2+int(math.log2(len(X))))]\n",
    "    recalls = BatchSorter(compressed, Q, X, G, Ts, metric=metric, batch_size=200).recall()\n",
    "    print(\"# searching!\")\n",
    "    recall_item_curve = []\n",
    "    print(\"expected items, overall time, avg recall, avg precision, avg error, avg items\")\n",
    "    for i, (t, recall) in enumerate(zip(Ts, recalls)):\n",
    "        print(\"{}, {}, {}, {}, {}, {}\".format(\n",
    "            2**i, 0, recall, recall * len(G[0]) / t, 0, t))\n",
    "        recall_item_curve.append(recall)\n",
    "    return recall_item_curve, recalls\n",
    "\n",
    "def parse_args():\n",
    "    # override default parameters with command line parameters\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='Process input method and parameters.')\n",
    "    parser.add_argument('--dataset', type=str, help='choose data set name')\n",
    "    parser.add_argument('--topk', type=int, help='required topk of ground truth')\n",
    "    parser.add_argument('--metric', type=str, help='metric of ground truth')\n",
    "    parser.add_argument('--num_codebook', type=int, help='number of codebooks')\n",
    "    parser.add_argument('--Ks', type=int, help='number of centroids in each quantizer')\n",
    "    args = parser.parse_args()\n",
    "    return args.dataset, args.topk, args.num_codebook, args.Ks, args.metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "0f5c0895",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_time = list(range(0,4))\n",
    "average_std = list(range(0,4))\n",
    "recall_Set = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "f4bcea89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrjmf\\AppData\\Local\\Temp\\ipykernel_9092\\1419328588.py:17: UserWarning: Using  Default Parameters \n",
      "  warnings.warn(\"Using  Default Parameters \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Parameters: dataset = netflix, topK = 20, codebook = 128, Ks = 100, metric = product\n",
      "# load the base data data/netflix/netflix_base.fvecs, \n",
      "# load the queries data/netflix/netflix_query.fvecs, \n",
      "# load the ground truth data/netflix/20_netflix_product_groundtruth.ivecs\n",
      "# ranking metric product\n",
      "# NormPQ, percentiles: 100, quantize: Subspace PQ, M: 127, Ks : 100, code_dtype: <class 'numpy.uint8'>\n",
      "#    Training the subspace: 0 / 127, 0 -> 3\n",
      "#    Training the subspace: 1 / 127, 3 -> 6\n",
      "#    Training the subspace: 2 / 127, 6 -> 9\n",
      "#    Training the subspace: 3 / 127, 9 -> 12\n",
      "#    Training the subspace: 4 / 127, 12 -> 15\n",
      "#    Training the subspace: 5 / 127, 15 -> 18\n",
      "#    Training the subspace: 6 / 127, 18 -> 21\n",
      "#    Training the subspace: 7 / 127, 21 -> 24\n",
      "#    Training the subspace: 8 / 127, 24 -> 27\n",
      "#    Training the subspace: 9 / 127, 27 -> 30\n",
      "#    Training the subspace: 10 / 127, 30 -> 33\n",
      "#    Training the subspace: 11 / 127, 33 -> 36\n",
      "#    Training the subspace: 12 / 127, 36 -> 39\n",
      "#    Training the subspace: 13 / 127, 39 -> 42\n",
      "#    Training the subspace: 14 / 127, 42 -> 45\n",
      "#    Training the subspace: 15 / 127, 45 -> 48\n",
      "#    Training the subspace: 16 / 127, 48 -> 51\n",
      "#    Training the subspace: 17 / 127, 51 -> 54\n",
      "#    Training the subspace: 18 / 127, 54 -> 57\n",
      "#    Training the subspace: 19 / 127, 57 -> 60\n",
      "#    Training the subspace: 20 / 127, 60 -> 63\n",
      "#    Training the subspace: 21 / 127, 63 -> 66\n",
      "#    Training the subspace: 22 / 127, 66 -> 69\n",
      "#    Training the subspace: 23 / 127, 69 -> 72\n",
      "#    Training the subspace: 24 / 127, 72 -> 75\n",
      "#    Training the subspace: 25 / 127, 75 -> 78\n",
      "#    Training the subspace: 26 / 127, 78 -> 81\n",
      "#    Training the subspace: 27 / 127, 81 -> 84\n",
      "#    Training the subspace: 28 / 127, 84 -> 87\n",
      "#    Training the subspace: 29 / 127, 87 -> 90\n",
      "#    Training the subspace: 30 / 127, 90 -> 93\n",
      "#    Training the subspace: 31 / 127, 93 -> 96\n",
      "#    Training the subspace: 32 / 127, 96 -> 99\n",
      "#    Training the subspace: 33 / 127, 99 -> 102\n",
      "#    Training the subspace: 34 / 127, 102 -> 105\n",
      "#    Training the subspace: 35 / 127, 105 -> 108\n",
      "#    Training the subspace: 36 / 127, 108 -> 111\n",
      "#    Training the subspace: 37 / 127, 111 -> 114\n",
      "#    Training the subspace: 38 / 127, 114 -> 117\n",
      "#    Training the subspace: 39 / 127, 117 -> 120\n",
      "#    Training the subspace: 40 / 127, 120 -> 123\n",
      "#    Training the subspace: 41 / 127, 123 -> 126\n",
      "#    Training the subspace: 42 / 127, 126 -> 129\n",
      "#    Training the subspace: 43 / 127, 129 -> 132\n",
      "#    Training the subspace: 44 / 127, 132 -> 135\n",
      "#    Training the subspace: 45 / 127, 135 -> 138\n",
      "#    Training the subspace: 46 / 127, 138 -> 140\n",
      "#    Training the subspace: 47 / 127, 140 -> 142\n",
      "#    Training the subspace: 48 / 127, 142 -> 144\n",
      "#    Training the subspace: 49 / 127, 144 -> 146\n",
      "#    Training the subspace: 50 / 127, 146 -> 148\n",
      "#    Training the subspace: 51 / 127, 148 -> 150\n",
      "#    Training the subspace: 52 / 127, 150 -> 152\n",
      "#    Training the subspace: 53 / 127, 152 -> 154\n",
      "#    Training the subspace: 54 / 127, 154 -> 156\n",
      "#    Training the subspace: 55 / 127, 156 -> 158\n",
      "#    Training the subspace: 56 / 127, 158 -> 160\n",
      "#    Training the subspace: 57 / 127, 160 -> 162\n",
      "#    Training the subspace: 58 / 127, 162 -> 164\n",
      "#    Training the subspace: 59 / 127, 164 -> 166\n",
      "#    Training the subspace: 60 / 127, 166 -> 168\n",
      "#    Training the subspace: 61 / 127, 168 -> 170\n",
      "#    Training the subspace: 62 / 127, 170 -> 172\n",
      "#    Training the subspace: 63 / 127, 172 -> 174\n",
      "#    Training the subspace: 64 / 127, 174 -> 176\n",
      "#    Training the subspace: 65 / 127, 176 -> 178\n",
      "#    Training the subspace: 66 / 127, 178 -> 180\n",
      "#    Training the subspace: 67 / 127, 180 -> 182\n",
      "#    Training the subspace: 68 / 127, 182 -> 184\n",
      "#    Training the subspace: 69 / 127, 184 -> 186\n",
      "#    Training the subspace: 70 / 127, 186 -> 188\n",
      "#    Training the subspace: 71 / 127, 188 -> 190\n",
      "#    Training the subspace: 72 / 127, 190 -> 192\n",
      "#    Training the subspace: 73 / 127, 192 -> 194\n",
      "#    Training the subspace: 74 / 127, 194 -> 196\n",
      "#    Training the subspace: 75 / 127, 196 -> 198\n",
      "#    Training the subspace: 76 / 127, 198 -> 200\n",
      "#    Training the subspace: 77 / 127, 200 -> 202\n",
      "#    Training the subspace: 78 / 127, 202 -> 204\n",
      "#    Training the subspace: 79 / 127, 204 -> 206\n",
      "#    Training the subspace: 80 / 127, 206 -> 208\n",
      "#    Training the subspace: 81 / 127, 208 -> 210\n",
      "#    Training the subspace: 82 / 127, 210 -> 212\n",
      "#    Training the subspace: 83 / 127, 212 -> 214\n",
      "#    Training the subspace: 84 / 127, 214 -> 216\n",
      "#    Training the subspace: 85 / 127, 216 -> 218\n",
      "#    Training the subspace: 86 / 127, 218 -> 220\n",
      "#    Training the subspace: 87 / 127, 220 -> 222\n",
      "#    Training the subspace: 88 / 127, 222 -> 224\n",
      "#    Training the subspace: 89 / 127, 224 -> 226\n",
      "#    Training the subspace: 90 / 127, 226 -> 228\n",
      "#    Training the subspace: 91 / 127, 228 -> 230\n",
      "#    Training the subspace: 92 / 127, 230 -> 232\n",
      "#    Training the subspace: 93 / 127, 232 -> 234\n",
      "#    Training the subspace: 94 / 127, 234 -> 236\n",
      "#    Training the subspace: 95 / 127, 236 -> 238\n",
      "#    Training the subspace: 96 / 127, 238 -> 240\n",
      "#    Training the subspace: 97 / 127, 240 -> 242\n",
      "#    Training the subspace: 98 / 127, 242 -> 244\n",
      "#    Training the subspace: 99 / 127, 244 -> 246\n",
      "#    Training the subspace: 100 / 127, 246 -> 248\n",
      "#    Training the subspace: 101 / 127, 248 -> 250\n",
      "#    Training the subspace: 102 / 127, 250 -> 252\n",
      "#    Training the subspace: 103 / 127, 252 -> 254\n",
      "#    Training the subspace: 104 / 127, 254 -> 256\n",
      "#    Training the subspace: 105 / 127, 256 -> 258\n",
      "#    Training the subspace: 106 / 127, 258 -> 260\n",
      "#    Training the subspace: 107 / 127, 260 -> 262\n",
      "#    Training the subspace: 108 / 127, 262 -> 264\n",
      "#    Training the subspace: 109 / 127, 264 -> 266\n",
      "#    Training the subspace: 110 / 127, 266 -> 268\n",
      "#    Training the subspace: 111 / 127, 268 -> 270\n",
      "#    Training the subspace: 112 / 127, 270 -> 272\n",
      "#    Training the subspace: 113 / 127, 272 -> 274\n",
      "#    Training the subspace: 114 / 127, 274 -> 276\n",
      "#    Training the subspace: 115 / 127, 276 -> 278\n",
      "#    Training the subspace: 116 / 127, 278 -> 280\n",
      "#    Training the subspace: 117 / 127, 280 -> 282\n",
      "#    Training the subspace: 118 / 127, 282 -> 284\n",
      "#    Training the subspace: 119 / 127, 284 -> 286\n",
      "#    Training the subspace: 120 / 127, 286 -> 288\n",
      "#    Training the subspace: 121 / 127, 288 -> 290\n",
      "#    Training the subspace: 122 / 127, 290 -> 292\n",
      "#    Training the subspace: 123 / 127, 292 -> 294\n",
      "#    Training the subspace: 124 / 127, 294 -> 296\n",
      "#    Training the subspace: 125 / 127, 296 -> 298\n",
      "#    Training the subspace: 126 / 127, 298 -> 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6637609 1.9822999 1.9080894 ... 1.8720485 1.9957652 2.0081244]\n",
      "# compress items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.47it/s]\n",
      " 20%|████████████████▍                                                               | 41/200 [00:00<00:00, 369.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sorting items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 368.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 363.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 359.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 363.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 379.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# searching!\n",
      "expected items, overall time, avg recall, avg precision, avg error, avg items\n",
      "1, 0, 0.0, 0.0, 0, 1\n",
      "2, 0, 0.0002, 0.002, 0, 2\n",
      "4, 0, 0.00025, 0.00125, 0, 4\n",
      "8, 0, 0.00055, 0.0013750000000000001, 0, 8\n",
      "16, 0, 0.00145, 0.0018124999999999999, 0, 16\n",
      "32, 0, 0.0021000000000000003, 0.0013125000000000003, 0, 32\n",
      "64, 0, 0.00425, 0.001328125, 0, 64\n",
      "128, 0, 0.011600000000000001, 0.0018125, 0, 128\n",
      "256, 0, 0.030600000000000002, 0.0023906250000000004, 0, 256\n",
      "512, 0, 0.060899999999999996, 0.00237890625, 0, 512\n",
      "1024, 0, 0.10085, 0.0019697265625, 0, 1024\n",
      "2048, 0, 0.1505, 0.0014697265625, 0, 2048\n",
      "4096, 0, 0.24694999999999998, 0.0012058105468749998, 0, 4096\n",
      "8192, 0, 0.43605, 0.0010645751953125, 0, 8192\n",
      "16384, 0, 0.89645, 0.00109429931640625, 0, 16384\n",
      "32768, 0, 1.0, 0.0006103515625, 0, 32768\n",
      "--- 17.468788862228394 seconds ---, iteration 1\n",
      "# ranking metric product\n",
      "# NormPQ, percentiles: 100, quantize: Subspace PQ, M: 127, Ks : 100, code_dtype: <class 'numpy.uint8'>\n",
      "#    Training the subspace: 0 / 127, 0 -> 3\n",
      "#    Training the subspace: 1 / 127, 3 -> 6\n",
      "#    Training the subspace: 2 / 127, 6 -> 9\n",
      "#    Training the subspace: 3 / 127, 9 -> 12\n",
      "#    Training the subspace: 4 / 127, 12 -> 15\n",
      "#    Training the subspace: 5 / 127, 15 -> 18\n",
      "#    Training the subspace: 6 / 127, 18 -> 21\n",
      "#    Training the subspace: 7 / 127, 21 -> 24\n",
      "#    Training the subspace: 8 / 127, 24 -> 27\n",
      "#    Training the subspace: 9 / 127, 27 -> 30\n",
      "#    Training the subspace: 10 / 127, 30 -> 33\n",
      "#    Training the subspace: 11 / 127, 33 -> 36\n",
      "#    Training the subspace: 12 / 127, 36 -> 39\n",
      "#    Training the subspace: 13 / 127, 39 -> 42\n",
      "#    Training the subspace: 14 / 127, 42 -> 45\n",
      "#    Training the subspace: 15 / 127, 45 -> 48\n",
      "#    Training the subspace: 16 / 127, 48 -> 51\n",
      "#    Training the subspace: 17 / 127, 51 -> 54\n",
      "#    Training the subspace: 18 / 127, 54 -> 57\n",
      "#    Training the subspace: 19 / 127, 57 -> 60\n",
      "#    Training the subspace: 20 / 127, 60 -> 63\n",
      "#    Training the subspace: 21 / 127, 63 -> 66\n",
      "#    Training the subspace: 22 / 127, 66 -> 69\n",
      "#    Training the subspace: 23 / 127, 69 -> 72\n",
      "#    Training the subspace: 24 / 127, 72 -> 75\n",
      "#    Training the subspace: 25 / 127, 75 -> 78\n",
      "#    Training the subspace: 26 / 127, 78 -> 81\n",
      "#    Training the subspace: 27 / 127, 81 -> 84\n",
      "#    Training the subspace: 28 / 127, 84 -> 87\n",
      "#    Training the subspace: 29 / 127, 87 -> 90\n",
      "#    Training the subspace: 30 / 127, 90 -> 93\n",
      "#    Training the subspace: 31 / 127, 93 -> 96\n",
      "#    Training the subspace: 32 / 127, 96 -> 99\n",
      "#    Training the subspace: 33 / 127, 99 -> 102\n",
      "#    Training the subspace: 34 / 127, 102 -> 105\n",
      "#    Training the subspace: 35 / 127, 105 -> 108\n",
      "#    Training the subspace: 36 / 127, 108 -> 111\n",
      "#    Training the subspace: 37 / 127, 111 -> 114\n",
      "#    Training the subspace: 38 / 127, 114 -> 117\n",
      "#    Training the subspace: 39 / 127, 117 -> 120\n",
      "#    Training the subspace: 40 / 127, 120 -> 123\n",
      "#    Training the subspace: 41 / 127, 123 -> 126\n",
      "#    Training the subspace: 42 / 127, 126 -> 129\n",
      "#    Training the subspace: 43 / 127, 129 -> 132\n",
      "#    Training the subspace: 44 / 127, 132 -> 135\n",
      "#    Training the subspace: 45 / 127, 135 -> 138\n",
      "#    Training the subspace: 46 / 127, 138 -> 140\n",
      "#    Training the subspace: 47 / 127, 140 -> 142\n",
      "#    Training the subspace: 48 / 127, 142 -> 144\n",
      "#    Training the subspace: 49 / 127, 144 -> 146\n",
      "#    Training the subspace: 50 / 127, 146 -> 148\n",
      "#    Training the subspace: 51 / 127, 148 -> 150\n",
      "#    Training the subspace: 52 / 127, 150 -> 152\n",
      "#    Training the subspace: 53 / 127, 152 -> 154\n",
      "#    Training the subspace: 54 / 127, 154 -> 156\n",
      "#    Training the subspace: 55 / 127, 156 -> 158\n",
      "#    Training the subspace: 56 / 127, 158 -> 160\n",
      "#    Training the subspace: 57 / 127, 160 -> 162\n",
      "#    Training the subspace: 58 / 127, 162 -> 164\n",
      "#    Training the subspace: 59 / 127, 164 -> 166\n",
      "#    Training the subspace: 60 / 127, 166 -> 168\n",
      "#    Training the subspace: 61 / 127, 168 -> 170\n",
      "#    Training the subspace: 62 / 127, 170 -> 172\n",
      "#    Training the subspace: 63 / 127, 172 -> 174\n",
      "#    Training the subspace: 64 / 127, 174 -> 176\n",
      "#    Training the subspace: 65 / 127, 176 -> 178\n",
      "#    Training the subspace: 66 / 127, 178 -> 180\n",
      "#    Training the subspace: 67 / 127, 180 -> 182\n",
      "#    Training the subspace: 68 / 127, 182 -> 184\n",
      "#    Training the subspace: 69 / 127, 184 -> 186\n",
      "#    Training the subspace: 70 / 127, 186 -> 188\n",
      "#    Training the subspace: 71 / 127, 188 -> 190\n",
      "#    Training the subspace: 72 / 127, 190 -> 192\n",
      "#    Training the subspace: 73 / 127, 192 -> 194\n",
      "#    Training the subspace: 74 / 127, 194 -> 196\n",
      "#    Training the subspace: 75 / 127, 196 -> 198\n",
      "#    Training the subspace: 76 / 127, 198 -> 200\n",
      "#    Training the subspace: 77 / 127, 200 -> 202\n",
      "#    Training the subspace: 78 / 127, 202 -> 204\n",
      "#    Training the subspace: 79 / 127, 204 -> 206\n",
      "#    Training the subspace: 80 / 127, 206 -> 208\n",
      "#    Training the subspace: 81 / 127, 208 -> 210\n",
      "#    Training the subspace: 82 / 127, 210 -> 212\n",
      "#    Training the subspace: 83 / 127, 212 -> 214\n",
      "#    Training the subspace: 84 / 127, 214 -> 216\n",
      "#    Training the subspace: 85 / 127, 216 -> 218\n",
      "#    Training the subspace: 86 / 127, 218 -> 220\n",
      "#    Training the subspace: 87 / 127, 220 -> 222\n",
      "#    Training the subspace: 88 / 127, 222 -> 224\n",
      "#    Training the subspace: 89 / 127, 224 -> 226\n",
      "#    Training the subspace: 90 / 127, 226 -> 228\n",
      "#    Training the subspace: 91 / 127, 228 -> 230\n",
      "#    Training the subspace: 92 / 127, 230 -> 232\n",
      "#    Training the subspace: 93 / 127, 232 -> 234\n",
      "#    Training the subspace: 94 / 127, 234 -> 236\n",
      "#    Training the subspace: 95 / 127, 236 -> 238\n",
      "#    Training the subspace: 96 / 127, 238 -> 240\n",
      "#    Training the subspace: 97 / 127, 240 -> 242\n",
      "#    Training the subspace: 98 / 127, 242 -> 244\n",
      "#    Training the subspace: 99 / 127, 244 -> 246\n",
      "#    Training the subspace: 100 / 127, 246 -> 248\n",
      "#    Training the subspace: 101 / 127, 248 -> 250\n",
      "#    Training the subspace: 102 / 127, 250 -> 252\n",
      "#    Training the subspace: 103 / 127, 252 -> 254\n",
      "#    Training the subspace: 104 / 127, 254 -> 256\n",
      "#    Training the subspace: 105 / 127, 256 -> 258\n",
      "#    Training the subspace: 106 / 127, 258 -> 260\n",
      "#    Training the subspace: 107 / 127, 260 -> 262\n",
      "#    Training the subspace: 108 / 127, 262 -> 264\n",
      "#    Training the subspace: 109 / 127, 264 -> 266\n",
      "#    Training the subspace: 110 / 127, 266 -> 268\n",
      "#    Training the subspace: 111 / 127, 268 -> 270\n",
      "#    Training the subspace: 112 / 127, 270 -> 272\n",
      "#    Training the subspace: 113 / 127, 272 -> 274\n",
      "#    Training the subspace: 114 / 127, 274 -> 276\n",
      "#    Training the subspace: 115 / 127, 276 -> 278\n",
      "#    Training the subspace: 116 / 127, 278 -> 280\n",
      "#    Training the subspace: 117 / 127, 280 -> 282\n",
      "#    Training the subspace: 118 / 127, 282 -> 284\n",
      "#    Training the subspace: 119 / 127, 284 -> 286\n",
      "#    Training the subspace: 120 / 127, 286 -> 288\n",
      "#    Training the subspace: 121 / 127, 288 -> 290\n",
      "#    Training the subspace: 122 / 127, 290 -> 292\n",
      "#    Training the subspace: 123 / 127, 292 -> 294\n",
      "#    Training the subspace: 124 / 127, 294 -> 296\n",
      "#    Training the subspace: 125 / 127, 296 -> 298\n",
      "#    Training the subspace: 126 / 127, 298 -> 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5786501 1.2892648 1.7862048 ... 1.7735262 1.9233481 1.8794478]\n",
      "# compress items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.45it/s]\n",
      " 21%|████████████████▊                                                               | 42/200 [00:00<00:00, 377.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sorting items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 377.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 364.55it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 367.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 362.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 369.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# searching!\n",
      "expected items, overall time, avg recall, avg precision, avg error, avg items\n",
      "1, 0, 0.0, 0.0, 0, 1\n",
      "2, 0, 0.0, 0.0, 0, 2\n",
      "4, 0, 0.0, 0.0, 0, 4\n",
      "8, 0, 5e-05, 0.000125, 0, 8\n",
      "16, 0, 0.00025, 0.0003125, 0, 16\n",
      "32, 0, 0.0007, 0.0004375, 0, 32\n",
      "64, 0, 0.004399999999999999, 0.001375, 0, 64\n",
      "128, 0, 0.01015, 0.0015859374999999999, 0, 128\n",
      "256, 0, 0.0174, 0.001359375, 0, 256\n",
      "512, 0, 0.0356, 0.001390625, 0, 512\n",
      "1024, 0, 0.07765000000000001, 0.0015166015625000002, 0, 1024\n",
      "2048, 0, 0.15925, 0.00155517578125, 0, 2048\n",
      "4096, 0, 0.27795, 0.0013571777343749998, 0, 4096\n",
      "8192, 0, 0.5028, 0.0012275390625000001, 0, 8192\n",
      "16384, 0, 0.9338, 0.001139892578125, 0, 16384\n",
      "32768, 0, 1.0, 0.0006103515625, 0, 32768\n",
      "--- 17.3514506816864 seconds ---, iteration 2\n",
      "# ranking metric product\n",
      "# NormPQ, percentiles: 100, quantize: Subspace PQ, M: 127, Ks : 100, code_dtype: <class 'numpy.uint8'>\n",
      "#    Training the subspace: 0 / 127, 0 -> 3\n",
      "#    Training the subspace: 1 / 127, 3 -> 6\n",
      "#    Training the subspace: 2 / 127, 6 -> 9\n",
      "#    Training the subspace: 3 / 127, 9 -> 12\n",
      "#    Training the subspace: 4 / 127, 12 -> 15\n",
      "#    Training the subspace: 5 / 127, 15 -> 18\n",
      "#    Training the subspace: 6 / 127, 18 -> 21\n",
      "#    Training the subspace: 7 / 127, 21 -> 24\n",
      "#    Training the subspace: 8 / 127, 24 -> 27\n",
      "#    Training the subspace: 9 / 127, 27 -> 30\n",
      "#    Training the subspace: 10 / 127, 30 -> 33\n",
      "#    Training the subspace: 11 / 127, 33 -> 36\n",
      "#    Training the subspace: 12 / 127, 36 -> 39\n",
      "#    Training the subspace: 13 / 127, 39 -> 42\n",
      "#    Training the subspace: 14 / 127, 42 -> 45\n",
      "#    Training the subspace: 15 / 127, 45 -> 48\n",
      "#    Training the subspace: 16 / 127, 48 -> 51\n",
      "#    Training the subspace: 17 / 127, 51 -> 54\n",
      "#    Training the subspace: 18 / 127, 54 -> 57\n",
      "#    Training the subspace: 19 / 127, 57 -> 60\n",
      "#    Training the subspace: 20 / 127, 60 -> 63\n",
      "#    Training the subspace: 21 / 127, 63 -> 66\n",
      "#    Training the subspace: 22 / 127, 66 -> 69\n",
      "#    Training the subspace: 23 / 127, 69 -> 72\n",
      "#    Training the subspace: 24 / 127, 72 -> 75\n",
      "#    Training the subspace: 25 / 127, 75 -> 78\n",
      "#    Training the subspace: 26 / 127, 78 -> 81\n",
      "#    Training the subspace: 27 / 127, 81 -> 84\n",
      "#    Training the subspace: 28 / 127, 84 -> 87\n",
      "#    Training the subspace: 29 / 127, 87 -> 90\n",
      "#    Training the subspace: 30 / 127, 90 -> 93\n",
      "#    Training the subspace: 31 / 127, 93 -> 96\n",
      "#    Training the subspace: 32 / 127, 96 -> 99\n",
      "#    Training the subspace: 33 / 127, 99 -> 102\n",
      "#    Training the subspace: 34 / 127, 102 -> 105\n",
      "#    Training the subspace: 35 / 127, 105 -> 108\n",
      "#    Training the subspace: 36 / 127, 108 -> 111\n",
      "#    Training the subspace: 37 / 127, 111 -> 114\n",
      "#    Training the subspace: 38 / 127, 114 -> 117\n",
      "#    Training the subspace: 39 / 127, 117 -> 120\n",
      "#    Training the subspace: 40 / 127, 120 -> 123\n",
      "#    Training the subspace: 41 / 127, 123 -> 126\n",
      "#    Training the subspace: 42 / 127, 126 -> 129\n",
      "#    Training the subspace: 43 / 127, 129 -> 132\n",
      "#    Training the subspace: 44 / 127, 132 -> 135\n",
      "#    Training the subspace: 45 / 127, 135 -> 138\n",
      "#    Training the subspace: 46 / 127, 138 -> 140\n",
      "#    Training the subspace: 47 / 127, 140 -> 142\n",
      "#    Training the subspace: 48 / 127, 142 -> 144\n",
      "#    Training the subspace: 49 / 127, 144 -> 146\n",
      "#    Training the subspace: 50 / 127, 146 -> 148\n",
      "#    Training the subspace: 51 / 127, 148 -> 150\n",
      "#    Training the subspace: 52 / 127, 150 -> 152\n",
      "#    Training the subspace: 53 / 127, 152 -> 154\n",
      "#    Training the subspace: 54 / 127, 154 -> 156\n",
      "#    Training the subspace: 55 / 127, 156 -> 158\n",
      "#    Training the subspace: 56 / 127, 158 -> 160\n",
      "#    Training the subspace: 57 / 127, 160 -> 162\n",
      "#    Training the subspace: 58 / 127, 162 -> 164\n",
      "#    Training the subspace: 59 / 127, 164 -> 166\n",
      "#    Training the subspace: 60 / 127, 166 -> 168\n",
      "#    Training the subspace: 61 / 127, 168 -> 170\n",
      "#    Training the subspace: 62 / 127, 170 -> 172\n",
      "#    Training the subspace: 63 / 127, 172 -> 174\n",
      "#    Training the subspace: 64 / 127, 174 -> 176\n",
      "#    Training the subspace: 65 / 127, 176 -> 178\n",
      "#    Training the subspace: 66 / 127, 178 -> 180\n",
      "#    Training the subspace: 67 / 127, 180 -> 182\n",
      "#    Training the subspace: 68 / 127, 182 -> 184\n",
      "#    Training the subspace: 69 / 127, 184 -> 186\n",
      "#    Training the subspace: 70 / 127, 186 -> 188\n",
      "#    Training the subspace: 71 / 127, 188 -> 190\n",
      "#    Training the subspace: 72 / 127, 190 -> 192\n",
      "#    Training the subspace: 73 / 127, 192 -> 194\n",
      "#    Training the subspace: 74 / 127, 194 -> 196\n",
      "#    Training the subspace: 75 / 127, 196 -> 198\n",
      "#    Training the subspace: 76 / 127, 198 -> 200\n",
      "#    Training the subspace: 77 / 127, 200 -> 202\n",
      "#    Training the subspace: 78 / 127, 202 -> 204\n",
      "#    Training the subspace: 79 / 127, 204 -> 206\n",
      "#    Training the subspace: 80 / 127, 206 -> 208\n",
      "#    Training the subspace: 81 / 127, 208 -> 210\n",
      "#    Training the subspace: 82 / 127, 210 -> 212\n",
      "#    Training the subspace: 83 / 127, 212 -> 214\n",
      "#    Training the subspace: 84 / 127, 214 -> 216\n",
      "#    Training the subspace: 85 / 127, 216 -> 218\n",
      "#    Training the subspace: 86 / 127, 218 -> 220\n",
      "#    Training the subspace: 87 / 127, 220 -> 222\n",
      "#    Training the subspace: 88 / 127, 222 -> 224\n",
      "#    Training the subspace: 89 / 127, 224 -> 226\n",
      "#    Training the subspace: 90 / 127, 226 -> 228\n",
      "#    Training the subspace: 91 / 127, 228 -> 230\n",
      "#    Training the subspace: 92 / 127, 230 -> 232\n",
      "#    Training the subspace: 93 / 127, 232 -> 234\n",
      "#    Training the subspace: 94 / 127, 234 -> 236\n",
      "#    Training the subspace: 95 / 127, 236 -> 238\n",
      "#    Training the subspace: 96 / 127, 238 -> 240\n",
      "#    Training the subspace: 97 / 127, 240 -> 242\n",
      "#    Training the subspace: 98 / 127, 242 -> 244\n",
      "#    Training the subspace: 99 / 127, 244 -> 246\n",
      "#    Training the subspace: 100 / 127, 246 -> 248\n",
      "#    Training the subspace: 101 / 127, 248 -> 250\n",
      "#    Training the subspace: 102 / 127, 250 -> 252\n",
      "#    Training the subspace: 103 / 127, 252 -> 254\n",
      "#    Training the subspace: 104 / 127, 254 -> 256\n",
      "#    Training the subspace: 105 / 127, 256 -> 258\n",
      "#    Training the subspace: 106 / 127, 258 -> 260\n",
      "#    Training the subspace: 107 / 127, 260 -> 262\n",
      "#    Training the subspace: 108 / 127, 262 -> 264\n",
      "#    Training the subspace: 109 / 127, 264 -> 266\n",
      "#    Training the subspace: 110 / 127, 266 -> 268\n",
      "#    Training the subspace: 111 / 127, 268 -> 270\n",
      "#    Training the subspace: 112 / 127, 270 -> 272\n",
      "#    Training the subspace: 113 / 127, 272 -> 274\n",
      "#    Training the subspace: 114 / 127, 274 -> 276\n",
      "#    Training the subspace: 115 / 127, 276 -> 278\n",
      "#    Training the subspace: 116 / 127, 278 -> 280\n",
      "#    Training the subspace: 117 / 127, 280 -> 282\n",
      "#    Training the subspace: 118 / 127, 282 -> 284\n",
      "#    Training the subspace: 119 / 127, 284 -> 286\n",
      "#    Training the subspace: 120 / 127, 286 -> 288\n",
      "#    Training the subspace: 121 / 127, 288 -> 290\n",
      "#    Training the subspace: 122 / 127, 290 -> 292\n",
      "#    Training the subspace: 123 / 127, 292 -> 294\n",
      "#    Training the subspace: 124 / 127, 294 -> 296\n",
      "#    Training the subspace: 125 / 127, 296 -> 298\n",
      "#    Training the subspace: 126 / 127, 298 -> 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8164606 1.6789181 1.7478566 ... 1.9829704 2.1905015 1.9070829]\n",
      "# compress items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.49it/s]\n",
      " 20%|████████████████                                                                | 40/200 [00:00<00:00, 360.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sorting items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 366.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 362.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 379.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 366.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 378.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# searching!\n",
      "expected items, overall time, avg recall, avg precision, avg error, avg items\n",
      "1, 0, 0.0, 0.0, 0, 1\n",
      "2, 0, 0.0001, 0.001, 0, 2\n",
      "4, 0, 0.0004, 0.002, 0, 4\n",
      "8, 0, 0.00125, 0.003125, 0, 8\n",
      "16, 0, 0.0023000000000000004, 0.0028750000000000004, 0, 16\n",
      "32, 0, 0.0038, 0.002375, 0, 32\n",
      "64, 0, 0.0070999999999999995, 0.00221875, 0, 64\n",
      "128, 0, 0.010899999999999998, 0.0017031249999999998, 0, 128\n",
      "256, 0, 0.01425, 0.0011132812500000001, 0, 256\n",
      "512, 0, 0.0197, 0.0007695312499999999, 0, 512\n",
      "1024, 0, 0.0316, 0.0006171875000000001, 0, 1024\n",
      "2048, 0, 0.07490000000000001, 0.0007314453125000001, 0, 2048\n",
      "4096, 0, 0.19865, 0.000969970703125, 0, 4096\n",
      "8192, 0, 0.43545, 0.0010631103515625, 0, 8192\n",
      "16384, 0, 0.86295, 0.00105340576171875, 0, 16384\n",
      "32768, 0, 1.0, 0.0006103515625, 0, 32768\n",
      "--- 17.30119490623474 seconds ---, iteration 3\n",
      "# ranking metric product\n",
      "# NormPQ, percentiles: 100, quantize: Subspace PQ, M: 127, Ks : 100, code_dtype: <class 'numpy.uint8'>\n",
      "#    Training the subspace: 0 / 127, 0 -> 3\n",
      "#    Training the subspace: 1 / 127, 3 -> 6\n",
      "#    Training the subspace: 2 / 127, 6 -> 9\n",
      "#    Training the subspace: 3 / 127, 9 -> 12\n",
      "#    Training the subspace: 4 / 127, 12 -> 15\n",
      "#    Training the subspace: 5 / 127, 15 -> 18\n",
      "#    Training the subspace: 6 / 127, 18 -> 21\n",
      "#    Training the subspace: 7 / 127, 21 -> 24\n",
      "#    Training the subspace: 8 / 127, 24 -> 27\n",
      "#    Training the subspace: 9 / 127, 27 -> 30\n",
      "#    Training the subspace: 10 / 127, 30 -> 33\n",
      "#    Training the subspace: 11 / 127, 33 -> 36\n",
      "#    Training the subspace: 12 / 127, 36 -> 39\n",
      "#    Training the subspace: 13 / 127, 39 -> 42\n",
      "#    Training the subspace: 14 / 127, 42 -> 45\n",
      "#    Training the subspace: 15 / 127, 45 -> 48\n",
      "#    Training the subspace: 16 / 127, 48 -> 51\n",
      "#    Training the subspace: 17 / 127, 51 -> 54\n",
      "#    Training the subspace: 18 / 127, 54 -> 57\n",
      "#    Training the subspace: 19 / 127, 57 -> 60\n",
      "#    Training the subspace: 20 / 127, 60 -> 63\n",
      "#    Training the subspace: 21 / 127, 63 -> 66\n",
      "#    Training the subspace: 22 / 127, 66 -> 69\n",
      "#    Training the subspace: 23 / 127, 69 -> 72\n",
      "#    Training the subspace: 24 / 127, 72 -> 75\n",
      "#    Training the subspace: 25 / 127, 75 -> 78\n",
      "#    Training the subspace: 26 / 127, 78 -> 81\n",
      "#    Training the subspace: 27 / 127, 81 -> 84\n",
      "#    Training the subspace: 28 / 127, 84 -> 87\n",
      "#    Training the subspace: 29 / 127, 87 -> 90\n",
      "#    Training the subspace: 30 / 127, 90 -> 93\n",
      "#    Training the subspace: 31 / 127, 93 -> 96\n",
      "#    Training the subspace: 32 / 127, 96 -> 99\n",
      "#    Training the subspace: 33 / 127, 99 -> 102\n",
      "#    Training the subspace: 34 / 127, 102 -> 105\n",
      "#    Training the subspace: 35 / 127, 105 -> 108\n",
      "#    Training the subspace: 36 / 127, 108 -> 111\n",
      "#    Training the subspace: 37 / 127, 111 -> 114\n",
      "#    Training the subspace: 38 / 127, 114 -> 117\n",
      "#    Training the subspace: 39 / 127, 117 -> 120\n",
      "#    Training the subspace: 40 / 127, 120 -> 123\n",
      "#    Training the subspace: 41 / 127, 123 -> 126\n",
      "#    Training the subspace: 42 / 127, 126 -> 129\n",
      "#    Training the subspace: 43 / 127, 129 -> 132\n",
      "#    Training the subspace: 44 / 127, 132 -> 135\n",
      "#    Training the subspace: 45 / 127, 135 -> 138\n",
      "#    Training the subspace: 46 / 127, 138 -> 140\n",
      "#    Training the subspace: 47 / 127, 140 -> 142\n",
      "#    Training the subspace: 48 / 127, 142 -> 144\n",
      "#    Training the subspace: 49 / 127, 144 -> 146\n",
      "#    Training the subspace: 50 / 127, 146 -> 148\n",
      "#    Training the subspace: 51 / 127, 148 -> 150\n",
      "#    Training the subspace: 52 / 127, 150 -> 152\n",
      "#    Training the subspace: 53 / 127, 152 -> 154\n",
      "#    Training the subspace: 54 / 127, 154 -> 156\n",
      "#    Training the subspace: 55 / 127, 156 -> 158\n",
      "#    Training the subspace: 56 / 127, 158 -> 160\n",
      "#    Training the subspace: 57 / 127, 160 -> 162\n",
      "#    Training the subspace: 58 / 127, 162 -> 164\n",
      "#    Training the subspace: 59 / 127, 164 -> 166\n",
      "#    Training the subspace: 60 / 127, 166 -> 168\n",
      "#    Training the subspace: 61 / 127, 168 -> 170\n",
      "#    Training the subspace: 62 / 127, 170 -> 172\n",
      "#    Training the subspace: 63 / 127, 172 -> 174\n",
      "#    Training the subspace: 64 / 127, 174 -> 176\n",
      "#    Training the subspace: 65 / 127, 176 -> 178\n",
      "#    Training the subspace: 66 / 127, 178 -> 180\n",
      "#    Training the subspace: 67 / 127, 180 -> 182\n",
      "#    Training the subspace: 68 / 127, 182 -> 184\n",
      "#    Training the subspace: 69 / 127, 184 -> 186\n",
      "#    Training the subspace: 70 / 127, 186 -> 188\n",
      "#    Training the subspace: 71 / 127, 188 -> 190\n",
      "#    Training the subspace: 72 / 127, 190 -> 192\n",
      "#    Training the subspace: 73 / 127, 192 -> 194\n",
      "#    Training the subspace: 74 / 127, 194 -> 196\n",
      "#    Training the subspace: 75 / 127, 196 -> 198\n",
      "#    Training the subspace: 76 / 127, 198 -> 200\n",
      "#    Training the subspace: 77 / 127, 200 -> 202\n",
      "#    Training the subspace: 78 / 127, 202 -> 204\n",
      "#    Training the subspace: 79 / 127, 204 -> 206\n",
      "#    Training the subspace: 80 / 127, 206 -> 208\n",
      "#    Training the subspace: 81 / 127, 208 -> 210\n",
      "#    Training the subspace: 82 / 127, 210 -> 212\n",
      "#    Training the subspace: 83 / 127, 212 -> 214\n",
      "#    Training the subspace: 84 / 127, 214 -> 216\n",
      "#    Training the subspace: 85 / 127, 216 -> 218\n",
      "#    Training the subspace: 86 / 127, 218 -> 220\n",
      "#    Training the subspace: 87 / 127, 220 -> 222\n",
      "#    Training the subspace: 88 / 127, 222 -> 224\n",
      "#    Training the subspace: 89 / 127, 224 -> 226\n",
      "#    Training the subspace: 90 / 127, 226 -> 228\n",
      "#    Training the subspace: 91 / 127, 228 -> 230\n",
      "#    Training the subspace: 92 / 127, 230 -> 232\n",
      "#    Training the subspace: 93 / 127, 232 -> 234\n",
      "#    Training the subspace: 94 / 127, 234 -> 236\n",
      "#    Training the subspace: 95 / 127, 236 -> 238\n",
      "#    Training the subspace: 96 / 127, 238 -> 240\n",
      "#    Training the subspace: 97 / 127, 240 -> 242\n",
      "#    Training the subspace: 98 / 127, 242 -> 244\n",
      "#    Training the subspace: 99 / 127, 244 -> 246\n",
      "#    Training the subspace: 100 / 127, 246 -> 248\n",
      "#    Training the subspace: 101 / 127, 248 -> 250\n",
      "#    Training the subspace: 102 / 127, 250 -> 252\n",
      "#    Training the subspace: 103 / 127, 252 -> 254\n",
      "#    Training the subspace: 104 / 127, 254 -> 256\n",
      "#    Training the subspace: 105 / 127, 256 -> 258\n",
      "#    Training the subspace: 106 / 127, 258 -> 260\n",
      "#    Training the subspace: 107 / 127, 260 -> 262\n",
      "#    Training the subspace: 108 / 127, 262 -> 264\n",
      "#    Training the subspace: 109 / 127, 264 -> 266\n",
      "#    Training the subspace: 110 / 127, 266 -> 268\n",
      "#    Training the subspace: 111 / 127, 268 -> 270\n",
      "#    Training the subspace: 112 / 127, 270 -> 272\n",
      "#    Training the subspace: 113 / 127, 272 -> 274\n",
      "#    Training the subspace: 114 / 127, 274 -> 276\n",
      "#    Training the subspace: 115 / 127, 276 -> 278\n",
      "#    Training the subspace: 116 / 127, 278 -> 280\n",
      "#    Training the subspace: 117 / 127, 280 -> 282\n",
      "#    Training the subspace: 118 / 127, 282 -> 284\n",
      "#    Training the subspace: 119 / 127, 284 -> 286\n",
      "#    Training the subspace: 120 / 127, 286 -> 288\n",
      "#    Training the subspace: 121 / 127, 288 -> 290\n",
      "#    Training the subspace: 122 / 127, 290 -> 292\n",
      "#    Training the subspace: 123 / 127, 292 -> 294\n",
      "#    Training the subspace: 124 / 127, 294 -> 296\n",
      "#    Training the subspace: 125 / 127, 296 -> 298\n",
      "#    Training the subspace: 126 / 127, 298 -> 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2555978 1.639479  2.084355  ... 2.0040414 1.7089437 2.149823 ]\n",
      "# compress items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.46it/s]\n",
      " 20%|████████████████                                                                | 40/200 [00:00<00:00, 354.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sorting items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 366.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 361.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 377.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 367.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 359.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# searching!\n",
      "expected items, overall time, avg recall, avg precision, avg error, avg items\n",
      "1, 0, 0.0, 0.0, 0, 1\n",
      "2, 0, 0.0, 0.0, 0, 2\n",
      "4, 0, 0.0, 0.0, 0, 4\n",
      "8, 0, 0.00025, 0.000625, 0, 8\n",
      "16, 0, 0.0004999999999999999, 0.0006249999999999999, 0, 16\n",
      "32, 0, 0.0014, 0.000875, 0, 32\n",
      "64, 0, 0.0025999999999999994, 0.0008124999999999999, 0, 64\n",
      "128, 0, 0.004900000000000001, 0.0007656250000000001, 0, 128\n",
      "256, 0, 0.00785, 0.0006132812499999999, 0, 256\n",
      "512, 0, 0.0152, 0.00059375, 0, 512\n",
      "1024, 0, 0.04275, 0.0008349609375000001, 0, 1024\n",
      "2048, 0, 0.13190000000000002, 0.0012880859375000002, 0, 2048\n",
      "4096, 0, 0.26630000000000004, 0.0013002929687500001, 0, 4096\n",
      "8192, 0, 0.487, 0.00118896484375, 0, 8192\n",
      "16384, 0, 0.9148499999999999, 0.0011167602539062498, 0, 16384\n",
      "32768, 0, 1.0, 0.0006103515625, 0, 32768\n",
      "--- 17.47195816040039 seconds ---, iteration 4\n",
      "# ranking metric product\n",
      "# NormPQ, percentiles: 100, quantize: Subspace PQ, M: 127, Ks : 100, code_dtype: <class 'numpy.uint8'>\n",
      "#    Training the subspace: 0 / 127, 0 -> 3\n",
      "#    Training the subspace: 1 / 127, 3 -> 6\n",
      "#    Training the subspace: 2 / 127, 6 -> 9\n",
      "#    Training the subspace: 3 / 127, 9 -> 12\n",
      "#    Training the subspace: 4 / 127, 12 -> 15\n",
      "#    Training the subspace: 5 / 127, 15 -> 18\n",
      "#    Training the subspace: 6 / 127, 18 -> 21\n",
      "#    Training the subspace: 7 / 127, 21 -> 24\n",
      "#    Training the subspace: 8 / 127, 24 -> 27\n",
      "#    Training the subspace: 9 / 127, 27 -> 30\n",
      "#    Training the subspace: 10 / 127, 30 -> 33\n",
      "#    Training the subspace: 11 / 127, 33 -> 36\n",
      "#    Training the subspace: 12 / 127, 36 -> 39\n",
      "#    Training the subspace: 13 / 127, 39 -> 42\n",
      "#    Training the subspace: 14 / 127, 42 -> 45\n",
      "#    Training the subspace: 15 / 127, 45 -> 48\n",
      "#    Training the subspace: 16 / 127, 48 -> 51\n",
      "#    Training the subspace: 17 / 127, 51 -> 54\n",
      "#    Training the subspace: 18 / 127, 54 -> 57\n",
      "#    Training the subspace: 19 / 127, 57 -> 60\n",
      "#    Training the subspace: 20 / 127, 60 -> 63\n",
      "#    Training the subspace: 21 / 127, 63 -> 66\n",
      "#    Training the subspace: 22 / 127, 66 -> 69\n",
      "#    Training the subspace: 23 / 127, 69 -> 72\n",
      "#    Training the subspace: 24 / 127, 72 -> 75\n",
      "#    Training the subspace: 25 / 127, 75 -> 78\n",
      "#    Training the subspace: 26 / 127, 78 -> 81\n",
      "#    Training the subspace: 27 / 127, 81 -> 84\n",
      "#    Training the subspace: 28 / 127, 84 -> 87\n",
      "#    Training the subspace: 29 / 127, 87 -> 90\n",
      "#    Training the subspace: 30 / 127, 90 -> 93\n",
      "#    Training the subspace: 31 / 127, 93 -> 96\n",
      "#    Training the subspace: 32 / 127, 96 -> 99\n",
      "#    Training the subspace: 33 / 127, 99 -> 102\n",
      "#    Training the subspace: 34 / 127, 102 -> 105\n",
      "#    Training the subspace: 35 / 127, 105 -> 108\n",
      "#    Training the subspace: 36 / 127, 108 -> 111\n",
      "#    Training the subspace: 37 / 127, 111 -> 114\n",
      "#    Training the subspace: 38 / 127, 114 -> 117\n",
      "#    Training the subspace: 39 / 127, 117 -> 120\n",
      "#    Training the subspace: 40 / 127, 120 -> 123\n",
      "#    Training the subspace: 41 / 127, 123 -> 126\n",
      "#    Training the subspace: 42 / 127, 126 -> 129\n",
      "#    Training the subspace: 43 / 127, 129 -> 132\n",
      "#    Training the subspace: 44 / 127, 132 -> 135\n",
      "#    Training the subspace: 45 / 127, 135 -> 138\n",
      "#    Training the subspace: 46 / 127, 138 -> 140\n",
      "#    Training the subspace: 47 / 127, 140 -> 142\n",
      "#    Training the subspace: 48 / 127, 142 -> 144\n",
      "#    Training the subspace: 49 / 127, 144 -> 146\n",
      "#    Training the subspace: 50 / 127, 146 -> 148\n",
      "#    Training the subspace: 51 / 127, 148 -> 150\n",
      "#    Training the subspace: 52 / 127, 150 -> 152\n",
      "#    Training the subspace: 53 / 127, 152 -> 154\n",
      "#    Training the subspace: 54 / 127, 154 -> 156\n",
      "#    Training the subspace: 55 / 127, 156 -> 158\n",
      "#    Training the subspace: 56 / 127, 158 -> 160\n",
      "#    Training the subspace: 57 / 127, 160 -> 162\n",
      "#    Training the subspace: 58 / 127, 162 -> 164\n",
      "#    Training the subspace: 59 / 127, 164 -> 166\n",
      "#    Training the subspace: 60 / 127, 166 -> 168\n",
      "#    Training the subspace: 61 / 127, 168 -> 170\n",
      "#    Training the subspace: 62 / 127, 170 -> 172\n",
      "#    Training the subspace: 63 / 127, 172 -> 174\n",
      "#    Training the subspace: 64 / 127, 174 -> 176\n",
      "#    Training the subspace: 65 / 127, 176 -> 178\n",
      "#    Training the subspace: 66 / 127, 178 -> 180\n",
      "#    Training the subspace: 67 / 127, 180 -> 182\n",
      "#    Training the subspace: 68 / 127, 182 -> 184\n",
      "#    Training the subspace: 69 / 127, 184 -> 186\n",
      "#    Training the subspace: 70 / 127, 186 -> 188\n",
      "#    Training the subspace: 71 / 127, 188 -> 190\n",
      "#    Training the subspace: 72 / 127, 190 -> 192\n",
      "#    Training the subspace: 73 / 127, 192 -> 194\n",
      "#    Training the subspace: 74 / 127, 194 -> 196\n",
      "#    Training the subspace: 75 / 127, 196 -> 198\n",
      "#    Training the subspace: 76 / 127, 198 -> 200\n",
      "#    Training the subspace: 77 / 127, 200 -> 202\n",
      "#    Training the subspace: 78 / 127, 202 -> 204\n",
      "#    Training the subspace: 79 / 127, 204 -> 206\n",
      "#    Training the subspace: 80 / 127, 206 -> 208\n",
      "#    Training the subspace: 81 / 127, 208 -> 210\n",
      "#    Training the subspace: 82 / 127, 210 -> 212\n",
      "#    Training the subspace: 83 / 127, 212 -> 214\n",
      "#    Training the subspace: 84 / 127, 214 -> 216\n",
      "#    Training the subspace: 85 / 127, 216 -> 218\n",
      "#    Training the subspace: 86 / 127, 218 -> 220\n",
      "#    Training the subspace: 87 / 127, 220 -> 222\n",
      "#    Training the subspace: 88 / 127, 222 -> 224\n",
      "#    Training the subspace: 89 / 127, 224 -> 226\n",
      "#    Training the subspace: 90 / 127, 226 -> 228\n",
      "#    Training the subspace: 91 / 127, 228 -> 230\n",
      "#    Training the subspace: 92 / 127, 230 -> 232\n",
      "#    Training the subspace: 93 / 127, 232 -> 234\n",
      "#    Training the subspace: 94 / 127, 234 -> 236\n",
      "#    Training the subspace: 95 / 127, 236 -> 238\n",
      "#    Training the subspace: 96 / 127, 238 -> 240\n",
      "#    Training the subspace: 97 / 127, 240 -> 242\n",
      "#    Training the subspace: 98 / 127, 242 -> 244\n",
      "#    Training the subspace: 99 / 127, 244 -> 246\n",
      "#    Training the subspace: 100 / 127, 246 -> 248\n",
      "#    Training the subspace: 101 / 127, 248 -> 250\n",
      "#    Training the subspace: 102 / 127, 250 -> 252\n",
      "#    Training the subspace: 103 / 127, 252 -> 254\n",
      "#    Training the subspace: 104 / 127, 254 -> 256\n",
      "#    Training the subspace: 105 / 127, 256 -> 258\n",
      "#    Training the subspace: 106 / 127, 258 -> 260\n",
      "#    Training the subspace: 107 / 127, 260 -> 262\n",
      "#    Training the subspace: 108 / 127, 262 -> 264\n",
      "#    Training the subspace: 109 / 127, 264 -> 266\n",
      "#    Training the subspace: 110 / 127, 266 -> 268\n",
      "#    Training the subspace: 111 / 127, 268 -> 270\n",
      "#    Training the subspace: 112 / 127, 270 -> 272\n",
      "#    Training the subspace: 113 / 127, 272 -> 274\n",
      "#    Training the subspace: 114 / 127, 274 -> 276\n",
      "#    Training the subspace: 115 / 127, 276 -> 278\n",
      "#    Training the subspace: 116 / 127, 278 -> 280\n",
      "#    Training the subspace: 117 / 127, 280 -> 282\n",
      "#    Training the subspace: 118 / 127, 282 -> 284\n",
      "#    Training the subspace: 119 / 127, 284 -> 286\n",
      "#    Training the subspace: 120 / 127, 286 -> 288\n",
      "#    Training the subspace: 121 / 127, 288 -> 290\n",
      "#    Training the subspace: 122 / 127, 290 -> 292\n",
      "#    Training the subspace: 123 / 127, 292 -> 294\n",
      "#    Training the subspace: 124 / 127, 294 -> 296\n",
      "#    Training the subspace: 125 / 127, 296 -> 298\n",
      "#    Training the subspace: 126 / 127, 298 -> 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7377948 1.3198137 1.759164  ... 2.0600932 2.0606556 1.7329253]\n",
      "# compress items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.39it/s]\n",
      " 20%|████████████████▍                                                               | 41/200 [00:00<00:00, 371.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sorting items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 358.09it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 368.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 354.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 377.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 367.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# searching!\n",
      "expected items, overall time, avg recall, avg precision, avg error, avg items\n",
      "1, 0, 0.0, 0.0, 0, 1\n",
      "2, 0, 0.0, 0.0, 0, 2\n",
      "4, 0, 0.0, 0.0, 0, 4\n",
      "8, 0, 0.0, 0.0, 0, 8\n",
      "16, 0, 5e-05, 6.25e-05, 0, 16\n",
      "32, 0, 0.0001, 6.25e-05, 0, 32\n",
      "64, 0, 0.00025, 7.8125e-05, 0, 64\n",
      "128, 0, 0.00065, 0.0001015625, 0, 128\n",
      "256, 0, 0.0022, 0.00017187500000000002, 0, 256\n",
      "512, 0, 0.0077, 0.00030078125, 0, 512\n",
      "1024, 0, 0.024849999999999997, 0.00048535156249999994, 0, 1024\n",
      "2048, 0, 0.06520000000000001, 0.0006367187500000001, 0, 2048\n",
      "4096, 0, 0.19615, 0.000957763671875, 0, 4096\n",
      "8192, 0, 0.47735, 0.0011654052734375, 0, 8192\n",
      "16384, 0, 0.9264499999999999, 0.0011309204101562498, 0, 16384\n",
      "32768, 0, 1.0, 0.0006103515625, 0, 32768\n",
      "--- 17.425189971923828 seconds ---, iteration 5\n",
      "# ranking metric product\n",
      "# NormPQ, percentiles: 100, quantize: Subspace PQ, M: 127, Ks : 100, code_dtype: <class 'numpy.uint8'>\n",
      "#    Training the subspace: 0 / 127, 0 -> 3\n",
      "#    Training the subspace: 1 / 127, 3 -> 6\n",
      "#    Training the subspace: 2 / 127, 6 -> 9\n",
      "#    Training the subspace: 3 / 127, 9 -> 12\n",
      "#    Training the subspace: 4 / 127, 12 -> 15\n",
      "#    Training the subspace: 5 / 127, 15 -> 18\n",
      "#    Training the subspace: 6 / 127, 18 -> 21\n",
      "#    Training the subspace: 7 / 127, 21 -> 24\n",
      "#    Training the subspace: 8 / 127, 24 -> 27\n",
      "#    Training the subspace: 9 / 127, 27 -> 30\n",
      "#    Training the subspace: 10 / 127, 30 -> 33\n",
      "#    Training the subspace: 11 / 127, 33 -> 36\n",
      "#    Training the subspace: 12 / 127, 36 -> 39\n",
      "#    Training the subspace: 13 / 127, 39 -> 42\n",
      "#    Training the subspace: 14 / 127, 42 -> 45\n",
      "#    Training the subspace: 15 / 127, 45 -> 48\n",
      "#    Training the subspace: 16 / 127, 48 -> 51\n",
      "#    Training the subspace: 17 / 127, 51 -> 54\n",
      "#    Training the subspace: 18 / 127, 54 -> 57\n",
      "#    Training the subspace: 19 / 127, 57 -> 60\n",
      "#    Training the subspace: 20 / 127, 60 -> 63\n",
      "#    Training the subspace: 21 / 127, 63 -> 66\n",
      "#    Training the subspace: 22 / 127, 66 -> 69\n",
      "#    Training the subspace: 23 / 127, 69 -> 72\n",
      "#    Training the subspace: 24 / 127, 72 -> 75\n",
      "#    Training the subspace: 25 / 127, 75 -> 78\n",
      "#    Training the subspace: 26 / 127, 78 -> 81\n",
      "#    Training the subspace: 27 / 127, 81 -> 84\n",
      "#    Training the subspace: 28 / 127, 84 -> 87\n",
      "#    Training the subspace: 29 / 127, 87 -> 90\n",
      "#    Training the subspace: 30 / 127, 90 -> 93\n",
      "#    Training the subspace: 31 / 127, 93 -> 96\n",
      "#    Training the subspace: 32 / 127, 96 -> 99\n",
      "#    Training the subspace: 33 / 127, 99 -> 102\n",
      "#    Training the subspace: 34 / 127, 102 -> 105\n",
      "#    Training the subspace: 35 / 127, 105 -> 108\n",
      "#    Training the subspace: 36 / 127, 108 -> 111\n",
      "#    Training the subspace: 37 / 127, 111 -> 114\n",
      "#    Training the subspace: 38 / 127, 114 -> 117\n",
      "#    Training the subspace: 39 / 127, 117 -> 120\n",
      "#    Training the subspace: 40 / 127, 120 -> 123\n",
      "#    Training the subspace: 41 / 127, 123 -> 126\n",
      "#    Training the subspace: 42 / 127, 126 -> 129\n",
      "#    Training the subspace: 43 / 127, 129 -> 132\n",
      "#    Training the subspace: 44 / 127, 132 -> 135\n",
      "#    Training the subspace: 45 / 127, 135 -> 138\n",
      "#    Training the subspace: 46 / 127, 138 -> 140\n",
      "#    Training the subspace: 47 / 127, 140 -> 142\n",
      "#    Training the subspace: 48 / 127, 142 -> 144\n",
      "#    Training the subspace: 49 / 127, 144 -> 146\n",
      "#    Training the subspace: 50 / 127, 146 -> 148\n",
      "#    Training the subspace: 51 / 127, 148 -> 150\n",
      "#    Training the subspace: 52 / 127, 150 -> 152\n",
      "#    Training the subspace: 53 / 127, 152 -> 154\n",
      "#    Training the subspace: 54 / 127, 154 -> 156\n",
      "#    Training the subspace: 55 / 127, 156 -> 158\n",
      "#    Training the subspace: 56 / 127, 158 -> 160\n",
      "#    Training the subspace: 57 / 127, 160 -> 162\n",
      "#    Training the subspace: 58 / 127, 162 -> 164\n",
      "#    Training the subspace: 59 / 127, 164 -> 166\n",
      "#    Training the subspace: 60 / 127, 166 -> 168\n",
      "#    Training the subspace: 61 / 127, 168 -> 170\n",
      "#    Training the subspace: 62 / 127, 170 -> 172\n",
      "#    Training the subspace: 63 / 127, 172 -> 174\n",
      "#    Training the subspace: 64 / 127, 174 -> 176\n",
      "#    Training the subspace: 65 / 127, 176 -> 178\n",
      "#    Training the subspace: 66 / 127, 178 -> 180\n",
      "#    Training the subspace: 67 / 127, 180 -> 182\n",
      "#    Training the subspace: 68 / 127, 182 -> 184\n",
      "#    Training the subspace: 69 / 127, 184 -> 186\n",
      "#    Training the subspace: 70 / 127, 186 -> 188\n",
      "#    Training the subspace: 71 / 127, 188 -> 190\n",
      "#    Training the subspace: 72 / 127, 190 -> 192\n",
      "#    Training the subspace: 73 / 127, 192 -> 194\n",
      "#    Training the subspace: 74 / 127, 194 -> 196\n",
      "#    Training the subspace: 75 / 127, 196 -> 198\n",
      "#    Training the subspace: 76 / 127, 198 -> 200\n",
      "#    Training the subspace: 77 / 127, 200 -> 202\n",
      "#    Training the subspace: 78 / 127, 202 -> 204\n",
      "#    Training the subspace: 79 / 127, 204 -> 206\n",
      "#    Training the subspace: 80 / 127, 206 -> 208\n",
      "#    Training the subspace: 81 / 127, 208 -> 210\n",
      "#    Training the subspace: 82 / 127, 210 -> 212\n",
      "#    Training the subspace: 83 / 127, 212 -> 214\n",
      "#    Training the subspace: 84 / 127, 214 -> 216\n",
      "#    Training the subspace: 85 / 127, 216 -> 218\n",
      "#    Training the subspace: 86 / 127, 218 -> 220\n",
      "#    Training the subspace: 87 / 127, 220 -> 222\n",
      "#    Training the subspace: 88 / 127, 222 -> 224\n",
      "#    Training the subspace: 89 / 127, 224 -> 226\n",
      "#    Training the subspace: 90 / 127, 226 -> 228\n",
      "#    Training the subspace: 91 / 127, 228 -> 230\n",
      "#    Training the subspace: 92 / 127, 230 -> 232\n",
      "#    Training the subspace: 93 / 127, 232 -> 234\n",
      "#    Training the subspace: 94 / 127, 234 -> 236\n",
      "#    Training the subspace: 95 / 127, 236 -> 238\n",
      "#    Training the subspace: 96 / 127, 238 -> 240\n",
      "#    Training the subspace: 97 / 127, 240 -> 242\n",
      "#    Training the subspace: 98 / 127, 242 -> 244\n",
      "#    Training the subspace: 99 / 127, 244 -> 246\n",
      "#    Training the subspace: 100 / 127, 246 -> 248\n",
      "#    Training the subspace: 101 / 127, 248 -> 250\n",
      "#    Training the subspace: 102 / 127, 250 -> 252\n",
      "#    Training the subspace: 103 / 127, 252 -> 254\n",
      "#    Training the subspace: 104 / 127, 254 -> 256\n",
      "#    Training the subspace: 105 / 127, 256 -> 258\n",
      "#    Training the subspace: 106 / 127, 258 -> 260\n",
      "#    Training the subspace: 107 / 127, 260 -> 262\n",
      "#    Training the subspace: 108 / 127, 262 -> 264\n",
      "#    Training the subspace: 109 / 127, 264 -> 266\n",
      "#    Training the subspace: 110 / 127, 266 -> 268\n",
      "#    Training the subspace: 111 / 127, 268 -> 270\n",
      "#    Training the subspace: 112 / 127, 270 -> 272\n",
      "#    Training the subspace: 113 / 127, 272 -> 274\n",
      "#    Training the subspace: 114 / 127, 274 -> 276\n",
      "#    Training the subspace: 115 / 127, 276 -> 278\n",
      "#    Training the subspace: 116 / 127, 278 -> 280\n",
      "#    Training the subspace: 117 / 127, 280 -> 282\n",
      "#    Training the subspace: 118 / 127, 282 -> 284\n",
      "#    Training the subspace: 119 / 127, 284 -> 286\n",
      "#    Training the subspace: 120 / 127, 286 -> 288\n",
      "#    Training the subspace: 121 / 127, 288 -> 290\n",
      "#    Training the subspace: 122 / 127, 290 -> 292\n",
      "#    Training the subspace: 123 / 127, 292 -> 294\n",
      "#    Training the subspace: 124 / 127, 294 -> 296\n",
      "#    Training the subspace: 125 / 127, 296 -> 298\n",
      "#    Training the subspace: 126 / 127, 298 -> 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.9127755 1.8760579 1.6213024 ... 1.8467962 1.4553537 1.8378358]\n",
      "# compress items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.46it/s]\n",
      " 20%|███████████████▌                                                                | 39/200 [00:00<00:00, 351.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sorting items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 361.55it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 365.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 378.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 375.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 367.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# searching!\n",
      "expected items, overall time, avg recall, avg precision, avg error, avg items\n",
      "1, 0, 0.0, 0.0, 0, 1\n",
      "2, 0, 0.0, 0.0, 0, 2\n",
      "4, 0, 0.0, 0.0, 0, 4\n",
      "8, 0, 0.0001, 0.00025, 0, 8\n",
      "16, 0, 0.0001, 0.000125, 0, 16\n",
      "32, 0, 0.00065, 0.00040625, 0, 32\n",
      "64, 0, 0.0036999999999999997, 0.00115625, 0, 64\n",
      "128, 0, 0.012700000000000001, 0.001984375, 0, 128\n",
      "256, 0, 0.02615, 0.00204296875, 0, 256\n",
      "512, 0, 0.0437, 0.0017070312500000002, 0, 512\n",
      "1024, 0, 0.06439999999999999, 0.0012578124999999998, 0, 1024\n",
      "2048, 0, 0.11485000000000001, 0.00112158203125, 0, 2048\n",
      "4096, 0, 0.23879999999999998, 0.001166015625, 0, 4096\n",
      "8192, 0, 0.47670000000000007, 0.001163818359375, 0, 8192\n",
      "16384, 0, 0.9504499999999999, 0.0011602172851562498, 0, 16384\n",
      "32768, 0, 1.0, 0.0006103515625, 0, 32768\n",
      "--- 17.328310251235962 seconds ---, iteration 6\n",
      "# ranking metric product\n",
      "# NormPQ, percentiles: 100, quantize: Subspace PQ, M: 127, Ks : 100, code_dtype: <class 'numpy.uint8'>\n",
      "#    Training the subspace: 0 / 127, 0 -> 3\n",
      "#    Training the subspace: 1 / 127, 3 -> 6\n",
      "#    Training the subspace: 2 / 127, 6 -> 9\n",
      "#    Training the subspace: 3 / 127, 9 -> 12\n",
      "#    Training the subspace: 4 / 127, 12 -> 15\n",
      "#    Training the subspace: 5 / 127, 15 -> 18\n",
      "#    Training the subspace: 6 / 127, 18 -> 21\n",
      "#    Training the subspace: 7 / 127, 21 -> 24\n",
      "#    Training the subspace: 8 / 127, 24 -> 27\n",
      "#    Training the subspace: 9 / 127, 27 -> 30\n",
      "#    Training the subspace: 10 / 127, 30 -> 33\n",
      "#    Training the subspace: 11 / 127, 33 -> 36\n",
      "#    Training the subspace: 12 / 127, 36 -> 39\n",
      "#    Training the subspace: 13 / 127, 39 -> 42\n",
      "#    Training the subspace: 14 / 127, 42 -> 45\n",
      "#    Training the subspace: 15 / 127, 45 -> 48\n",
      "#    Training the subspace: 16 / 127, 48 -> 51\n",
      "#    Training the subspace: 17 / 127, 51 -> 54\n",
      "#    Training the subspace: 18 / 127, 54 -> 57\n",
      "#    Training the subspace: 19 / 127, 57 -> 60\n",
      "#    Training the subspace: 20 / 127, 60 -> 63\n",
      "#    Training the subspace: 21 / 127, 63 -> 66\n",
      "#    Training the subspace: 22 / 127, 66 -> 69\n",
      "#    Training the subspace: 23 / 127, 69 -> 72\n",
      "#    Training the subspace: 24 / 127, 72 -> 75\n",
      "#    Training the subspace: 25 / 127, 75 -> 78\n",
      "#    Training the subspace: 26 / 127, 78 -> 81\n",
      "#    Training the subspace: 27 / 127, 81 -> 84\n",
      "#    Training the subspace: 28 / 127, 84 -> 87\n",
      "#    Training the subspace: 29 / 127, 87 -> 90\n",
      "#    Training the subspace: 30 / 127, 90 -> 93\n",
      "#    Training the subspace: 31 / 127, 93 -> 96\n",
      "#    Training the subspace: 32 / 127, 96 -> 99\n",
      "#    Training the subspace: 33 / 127, 99 -> 102\n",
      "#    Training the subspace: 34 / 127, 102 -> 105\n",
      "#    Training the subspace: 35 / 127, 105 -> 108\n",
      "#    Training the subspace: 36 / 127, 108 -> 111\n",
      "#    Training the subspace: 37 / 127, 111 -> 114\n",
      "#    Training the subspace: 38 / 127, 114 -> 117\n",
      "#    Training the subspace: 39 / 127, 117 -> 120\n",
      "#    Training the subspace: 40 / 127, 120 -> 123\n",
      "#    Training the subspace: 41 / 127, 123 -> 126\n",
      "#    Training the subspace: 42 / 127, 126 -> 129\n",
      "#    Training the subspace: 43 / 127, 129 -> 132\n",
      "#    Training the subspace: 44 / 127, 132 -> 135\n",
      "#    Training the subspace: 45 / 127, 135 -> 138\n",
      "#    Training the subspace: 46 / 127, 138 -> 140\n",
      "#    Training the subspace: 47 / 127, 140 -> 142\n",
      "#    Training the subspace: 48 / 127, 142 -> 144\n",
      "#    Training the subspace: 49 / 127, 144 -> 146\n",
      "#    Training the subspace: 50 / 127, 146 -> 148\n",
      "#    Training the subspace: 51 / 127, 148 -> 150\n",
      "#    Training the subspace: 52 / 127, 150 -> 152\n",
      "#    Training the subspace: 53 / 127, 152 -> 154\n",
      "#    Training the subspace: 54 / 127, 154 -> 156\n",
      "#    Training the subspace: 55 / 127, 156 -> 158\n",
      "#    Training the subspace: 56 / 127, 158 -> 160\n",
      "#    Training the subspace: 57 / 127, 160 -> 162\n",
      "#    Training the subspace: 58 / 127, 162 -> 164\n",
      "#    Training the subspace: 59 / 127, 164 -> 166\n",
      "#    Training the subspace: 60 / 127, 166 -> 168\n",
      "#    Training the subspace: 61 / 127, 168 -> 170\n",
      "#    Training the subspace: 62 / 127, 170 -> 172\n",
      "#    Training the subspace: 63 / 127, 172 -> 174\n",
      "#    Training the subspace: 64 / 127, 174 -> 176\n",
      "#    Training the subspace: 65 / 127, 176 -> 178\n",
      "#    Training the subspace: 66 / 127, 178 -> 180\n",
      "#    Training the subspace: 67 / 127, 180 -> 182\n",
      "#    Training the subspace: 68 / 127, 182 -> 184\n",
      "#    Training the subspace: 69 / 127, 184 -> 186\n",
      "#    Training the subspace: 70 / 127, 186 -> 188\n",
      "#    Training the subspace: 71 / 127, 188 -> 190\n",
      "#    Training the subspace: 72 / 127, 190 -> 192\n",
      "#    Training the subspace: 73 / 127, 192 -> 194\n",
      "#    Training the subspace: 74 / 127, 194 -> 196\n",
      "#    Training the subspace: 75 / 127, 196 -> 198\n",
      "#    Training the subspace: 76 / 127, 198 -> 200\n",
      "#    Training the subspace: 77 / 127, 200 -> 202\n",
      "#    Training the subspace: 78 / 127, 202 -> 204\n",
      "#    Training the subspace: 79 / 127, 204 -> 206\n",
      "#    Training the subspace: 80 / 127, 206 -> 208\n",
      "#    Training the subspace: 81 / 127, 208 -> 210\n",
      "#    Training the subspace: 82 / 127, 210 -> 212\n",
      "#    Training the subspace: 83 / 127, 212 -> 214\n",
      "#    Training the subspace: 84 / 127, 214 -> 216\n",
      "#    Training the subspace: 85 / 127, 216 -> 218\n",
      "#    Training the subspace: 86 / 127, 218 -> 220\n",
      "#    Training the subspace: 87 / 127, 220 -> 222\n",
      "#    Training the subspace: 88 / 127, 222 -> 224\n",
      "#    Training the subspace: 89 / 127, 224 -> 226\n",
      "#    Training the subspace: 90 / 127, 226 -> 228\n",
      "#    Training the subspace: 91 / 127, 228 -> 230\n",
      "#    Training the subspace: 92 / 127, 230 -> 232\n",
      "#    Training the subspace: 93 / 127, 232 -> 234\n",
      "#    Training the subspace: 94 / 127, 234 -> 236\n",
      "#    Training the subspace: 95 / 127, 236 -> 238\n",
      "#    Training the subspace: 96 / 127, 238 -> 240\n",
      "#    Training the subspace: 97 / 127, 240 -> 242\n",
      "#    Training the subspace: 98 / 127, 242 -> 244\n",
      "#    Training the subspace: 99 / 127, 244 -> 246\n",
      "#    Training the subspace: 100 / 127, 246 -> 248\n",
      "#    Training the subspace: 101 / 127, 248 -> 250\n",
      "#    Training the subspace: 102 / 127, 250 -> 252\n",
      "#    Training the subspace: 103 / 127, 252 -> 254\n",
      "#    Training the subspace: 104 / 127, 254 -> 256\n",
      "#    Training the subspace: 105 / 127, 256 -> 258\n",
      "#    Training the subspace: 106 / 127, 258 -> 260\n",
      "#    Training the subspace: 107 / 127, 260 -> 262\n",
      "#    Training the subspace: 108 / 127, 262 -> 264\n",
      "#    Training the subspace: 109 / 127, 264 -> 266\n",
      "#    Training the subspace: 110 / 127, 266 -> 268\n",
      "#    Training the subspace: 111 / 127, 268 -> 270\n",
      "#    Training the subspace: 112 / 127, 270 -> 272\n",
      "#    Training the subspace: 113 / 127, 272 -> 274\n",
      "#    Training the subspace: 114 / 127, 274 -> 276\n",
      "#    Training the subspace: 115 / 127, 276 -> 278\n",
      "#    Training the subspace: 116 / 127, 278 -> 280\n",
      "#    Training the subspace: 117 / 127, 280 -> 282\n",
      "#    Training the subspace: 118 / 127, 282 -> 284\n",
      "#    Training the subspace: 119 / 127, 284 -> 286\n",
      "#    Training the subspace: 120 / 127, 286 -> 288\n",
      "#    Training the subspace: 121 / 127, 288 -> 290\n",
      "#    Training the subspace: 122 / 127, 290 -> 292\n",
      "#    Training the subspace: 123 / 127, 292 -> 294\n",
      "#    Training the subspace: 124 / 127, 294 -> 296\n",
      "#    Training the subspace: 125 / 127, 296 -> 298\n",
      "#    Training the subspace: 126 / 127, 298 -> 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3865273 1.7224396 2.0722234 ... 1.8359447 1.5980005 1.5671581]\n",
      "# compress items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.52it/s]\n",
      " 20%|████████████████▍                                                               | 41/200 [00:00<00:00, 367.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sorting items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 363.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 377.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 378.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 369.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 364.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# searching!\n",
      "expected items, overall time, avg recall, avg precision, avg error, avg items\n",
      "1, 0, 0.0, 0.0, 0, 1\n",
      "2, 0, 0.0, 0.0, 0, 2\n",
      "4, 0, 0.0001, 0.0005, 0, 4\n",
      "8, 0, 0.0001, 0.00025, 0, 8\n",
      "16, 0, 0.0002, 0.00025, 0, 16\n",
      "32, 0, 0.00055, 0.00034375000000000003, 0, 32\n",
      "64, 0, 0.00115, 0.000359375, 0, 64\n",
      "128, 0, 0.00275, 0.00042968749999999995, 0, 128\n",
      "256, 0, 0.0072499999999999995, 0.00056640625, 0, 256\n",
      "512, 0, 0.018449999999999998, 0.0007207031249999999, 0, 512\n",
      "1024, 0, 0.04939999999999999, 0.0009648437499999999, 0, 1024\n",
      "2048, 0, 0.11785, 0.0011508789062499999, 0, 2048\n",
      "4096, 0, 0.2291, 0.00111865234375, 0, 4096\n",
      "8192, 0, 0.4574, 0.00111669921875, 0, 8192\n",
      "16384, 0, 0.9509000000000001, 0.0011607666015625, 0, 16384\n",
      "32768, 0, 1.0, 0.0006103515625, 0, 32768\n",
      "--- 17.314263582229614 seconds ---, iteration 7\n",
      "# ranking metric product\n",
      "# NormPQ, percentiles: 100, quantize: Subspace PQ, M: 127, Ks : 100, code_dtype: <class 'numpy.uint8'>\n",
      "#    Training the subspace: 0 / 127, 0 -> 3\n",
      "#    Training the subspace: 1 / 127, 3 -> 6\n",
      "#    Training the subspace: 2 / 127, 6 -> 9\n",
      "#    Training the subspace: 3 / 127, 9 -> 12\n",
      "#    Training the subspace: 4 / 127, 12 -> 15\n",
      "#    Training the subspace: 5 / 127, 15 -> 18\n",
      "#    Training the subspace: 6 / 127, 18 -> 21\n",
      "#    Training the subspace: 7 / 127, 21 -> 24\n",
      "#    Training the subspace: 8 / 127, 24 -> 27\n",
      "#    Training the subspace: 9 / 127, 27 -> 30\n",
      "#    Training the subspace: 10 / 127, 30 -> 33\n",
      "#    Training the subspace: 11 / 127, 33 -> 36\n",
      "#    Training the subspace: 12 / 127, 36 -> 39\n",
      "#    Training the subspace: 13 / 127, 39 -> 42\n",
      "#    Training the subspace: 14 / 127, 42 -> 45\n",
      "#    Training the subspace: 15 / 127, 45 -> 48\n",
      "#    Training the subspace: 16 / 127, 48 -> 51\n",
      "#    Training the subspace: 17 / 127, 51 -> 54\n",
      "#    Training the subspace: 18 / 127, 54 -> 57\n",
      "#    Training the subspace: 19 / 127, 57 -> 60\n",
      "#    Training the subspace: 20 / 127, 60 -> 63\n",
      "#    Training the subspace: 21 / 127, 63 -> 66\n",
      "#    Training the subspace: 22 / 127, 66 -> 69\n",
      "#    Training the subspace: 23 / 127, 69 -> 72\n",
      "#    Training the subspace: 24 / 127, 72 -> 75\n",
      "#    Training the subspace: 25 / 127, 75 -> 78\n",
      "#    Training the subspace: 26 / 127, 78 -> 81\n",
      "#    Training the subspace: 27 / 127, 81 -> 84\n",
      "#    Training the subspace: 28 / 127, 84 -> 87\n",
      "#    Training the subspace: 29 / 127, 87 -> 90\n",
      "#    Training the subspace: 30 / 127, 90 -> 93\n",
      "#    Training the subspace: 31 / 127, 93 -> 96\n",
      "#    Training the subspace: 32 / 127, 96 -> 99\n",
      "#    Training the subspace: 33 / 127, 99 -> 102\n",
      "#    Training the subspace: 34 / 127, 102 -> 105\n",
      "#    Training the subspace: 35 / 127, 105 -> 108\n",
      "#    Training the subspace: 36 / 127, 108 -> 111\n",
      "#    Training the subspace: 37 / 127, 111 -> 114\n",
      "#    Training the subspace: 38 / 127, 114 -> 117\n",
      "#    Training the subspace: 39 / 127, 117 -> 120\n",
      "#    Training the subspace: 40 / 127, 120 -> 123\n",
      "#    Training the subspace: 41 / 127, 123 -> 126\n",
      "#    Training the subspace: 42 / 127, 126 -> 129\n",
      "#    Training the subspace: 43 / 127, 129 -> 132\n",
      "#    Training the subspace: 44 / 127, 132 -> 135\n",
      "#    Training the subspace: 45 / 127, 135 -> 138\n",
      "#    Training the subspace: 46 / 127, 138 -> 140\n",
      "#    Training the subspace: 47 / 127, 140 -> 142\n",
      "#    Training the subspace: 48 / 127, 142 -> 144\n",
      "#    Training the subspace: 49 / 127, 144 -> 146\n",
      "#    Training the subspace: 50 / 127, 146 -> 148\n",
      "#    Training the subspace: 51 / 127, 148 -> 150\n",
      "#    Training the subspace: 52 / 127, 150 -> 152\n",
      "#    Training the subspace: 53 / 127, 152 -> 154\n",
      "#    Training the subspace: 54 / 127, 154 -> 156\n",
      "#    Training the subspace: 55 / 127, 156 -> 158\n",
      "#    Training the subspace: 56 / 127, 158 -> 160\n",
      "#    Training the subspace: 57 / 127, 160 -> 162\n",
      "#    Training the subspace: 58 / 127, 162 -> 164\n",
      "#    Training the subspace: 59 / 127, 164 -> 166\n",
      "#    Training the subspace: 60 / 127, 166 -> 168\n",
      "#    Training the subspace: 61 / 127, 168 -> 170\n",
      "#    Training the subspace: 62 / 127, 170 -> 172\n",
      "#    Training the subspace: 63 / 127, 172 -> 174\n",
      "#    Training the subspace: 64 / 127, 174 -> 176\n",
      "#    Training the subspace: 65 / 127, 176 -> 178\n",
      "#    Training the subspace: 66 / 127, 178 -> 180\n",
      "#    Training the subspace: 67 / 127, 180 -> 182\n",
      "#    Training the subspace: 68 / 127, 182 -> 184\n",
      "#    Training the subspace: 69 / 127, 184 -> 186\n",
      "#    Training the subspace: 70 / 127, 186 -> 188\n",
      "#    Training the subspace: 71 / 127, 188 -> 190\n",
      "#    Training the subspace: 72 / 127, 190 -> 192\n",
      "#    Training the subspace: 73 / 127, 192 -> 194\n",
      "#    Training the subspace: 74 / 127, 194 -> 196\n",
      "#    Training the subspace: 75 / 127, 196 -> 198\n",
      "#    Training the subspace: 76 / 127, 198 -> 200\n",
      "#    Training the subspace: 77 / 127, 200 -> 202\n",
      "#    Training the subspace: 78 / 127, 202 -> 204\n",
      "#    Training the subspace: 79 / 127, 204 -> 206\n",
      "#    Training the subspace: 80 / 127, 206 -> 208\n",
      "#    Training the subspace: 81 / 127, 208 -> 210\n",
      "#    Training the subspace: 82 / 127, 210 -> 212\n",
      "#    Training the subspace: 83 / 127, 212 -> 214\n",
      "#    Training the subspace: 84 / 127, 214 -> 216\n",
      "#    Training the subspace: 85 / 127, 216 -> 218\n",
      "#    Training the subspace: 86 / 127, 218 -> 220\n",
      "#    Training the subspace: 87 / 127, 220 -> 222\n",
      "#    Training the subspace: 88 / 127, 222 -> 224\n",
      "#    Training the subspace: 89 / 127, 224 -> 226\n",
      "#    Training the subspace: 90 / 127, 226 -> 228\n",
      "#    Training the subspace: 91 / 127, 228 -> 230\n",
      "#    Training the subspace: 92 / 127, 230 -> 232\n",
      "#    Training the subspace: 93 / 127, 232 -> 234\n",
      "#    Training the subspace: 94 / 127, 234 -> 236\n",
      "#    Training the subspace: 95 / 127, 236 -> 238\n",
      "#    Training the subspace: 96 / 127, 238 -> 240\n",
      "#    Training the subspace: 97 / 127, 240 -> 242\n",
      "#    Training the subspace: 98 / 127, 242 -> 244\n",
      "#    Training the subspace: 99 / 127, 244 -> 246\n",
      "#    Training the subspace: 100 / 127, 246 -> 248\n",
      "#    Training the subspace: 101 / 127, 248 -> 250\n",
      "#    Training the subspace: 102 / 127, 250 -> 252\n",
      "#    Training the subspace: 103 / 127, 252 -> 254\n",
      "#    Training the subspace: 104 / 127, 254 -> 256\n",
      "#    Training the subspace: 105 / 127, 256 -> 258\n",
      "#    Training the subspace: 106 / 127, 258 -> 260\n",
      "#    Training the subspace: 107 / 127, 260 -> 262\n",
      "#    Training the subspace: 108 / 127, 262 -> 264\n",
      "#    Training the subspace: 109 / 127, 264 -> 266\n",
      "#    Training the subspace: 110 / 127, 266 -> 268\n",
      "#    Training the subspace: 111 / 127, 268 -> 270\n",
      "#    Training the subspace: 112 / 127, 270 -> 272\n",
      "#    Training the subspace: 113 / 127, 272 -> 274\n",
      "#    Training the subspace: 114 / 127, 274 -> 276\n",
      "#    Training the subspace: 115 / 127, 276 -> 278\n",
      "#    Training the subspace: 116 / 127, 278 -> 280\n",
      "#    Training the subspace: 117 / 127, 280 -> 282\n",
      "#    Training the subspace: 118 / 127, 282 -> 284\n",
      "#    Training the subspace: 119 / 127, 284 -> 286\n",
      "#    Training the subspace: 120 / 127, 286 -> 288\n",
      "#    Training the subspace: 121 / 127, 288 -> 290\n",
      "#    Training the subspace: 122 / 127, 290 -> 292\n",
      "#    Training the subspace: 123 / 127, 292 -> 294\n",
      "#    Training the subspace: 124 / 127, 294 -> 296\n",
      "#    Training the subspace: 125 / 127, 296 -> 298\n",
      "#    Training the subspace: 126 / 127, 298 -> 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8740349 2.0801687 1.5813056 ... 1.7159473 1.9450052 1.7945737]\n",
      "# compress items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.46it/s]\n",
      " 20%|████████████████▍                                                               | 41/200 [00:00<00:00, 371.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sorting items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 367.26it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 377.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 375.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 318.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 308.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# searching!\n",
      "expected items, overall time, avg recall, avg precision, avg error, avg items\n",
      "1, 0, 0.0, 0.0, 0, 1\n",
      "2, 0, 0.0, 0.0, 0, 2\n",
      "4, 0, 5e-05, 0.00025, 0, 4\n",
      "8, 0, 5e-05, 0.000125, 0, 8\n",
      "16, 0, 0.00015000000000000001, 0.0001875, 0, 16\n",
      "32, 0, 0.00044999999999999993, 0.00028125, 0, 32\n",
      "64, 0, 0.00095, 0.000296875, 0, 64\n",
      "128, 0, 0.0024500000000000004, 0.00038281250000000007, 0, 128\n",
      "256, 0, 0.006700000000000001, 0.0005234375, 0, 256\n",
      "512, 0, 0.016149999999999998, 0.0006308593749999999, 0, 512\n",
      "1024, 0, 0.04095, 0.0007998046875, 0, 1024\n",
      "2048, 0, 0.0881, 0.0008603515625, 0, 2048\n",
      "4096, 0, 0.18915, 0.0009235839843750001, 0, 4096\n",
      "8192, 0, 0.4543, 0.001109130859375, 0, 8192\n",
      "16384, 0, 0.9131999999999999, 0.00111474609375, 0, 16384\n",
      "32768, 0, 1.0, 0.0006103515625, 0, 32768\n",
      "--- 17.59346342086792 seconds ---, iteration 8\n",
      "# ranking metric product\n",
      "# NormPQ, percentiles: 100, quantize: Subspace PQ, M: 127, Ks : 100, code_dtype: <class 'numpy.uint8'>\n",
      "#    Training the subspace: 0 / 127, 0 -> 3\n",
      "#    Training the subspace: 1 / 127, 3 -> 6\n",
      "#    Training the subspace: 2 / 127, 6 -> 9\n",
      "#    Training the subspace: 3 / 127, 9 -> 12\n",
      "#    Training the subspace: 4 / 127, 12 -> 15\n",
      "#    Training the subspace: 5 / 127, 15 -> 18\n",
      "#    Training the subspace: 6 / 127, 18 -> 21\n",
      "#    Training the subspace: 7 / 127, 21 -> 24\n",
      "#    Training the subspace: 8 / 127, 24 -> 27\n",
      "#    Training the subspace: 9 / 127, 27 -> 30\n",
      "#    Training the subspace: 10 / 127, 30 -> 33\n",
      "#    Training the subspace: 11 / 127, 33 -> 36\n",
      "#    Training the subspace: 12 / 127, 36 -> 39\n",
      "#    Training the subspace: 13 / 127, 39 -> 42\n",
      "#    Training the subspace: 14 / 127, 42 -> 45\n",
      "#    Training the subspace: 15 / 127, 45 -> 48\n",
      "#    Training the subspace: 16 / 127, 48 -> 51\n",
      "#    Training the subspace: 17 / 127, 51 -> 54\n",
      "#    Training the subspace: 18 / 127, 54 -> 57\n",
      "#    Training the subspace: 19 / 127, 57 -> 60\n",
      "#    Training the subspace: 20 / 127, 60 -> 63\n",
      "#    Training the subspace: 21 / 127, 63 -> 66\n",
      "#    Training the subspace: 22 / 127, 66 -> 69\n",
      "#    Training the subspace: 23 / 127, 69 -> 72\n",
      "#    Training the subspace: 24 / 127, 72 -> 75\n",
      "#    Training the subspace: 25 / 127, 75 -> 78\n",
      "#    Training the subspace: 26 / 127, 78 -> 81\n",
      "#    Training the subspace: 27 / 127, 81 -> 84\n",
      "#    Training the subspace: 28 / 127, 84 -> 87\n",
      "#    Training the subspace: 29 / 127, 87 -> 90\n",
      "#    Training the subspace: 30 / 127, 90 -> 93\n",
      "#    Training the subspace: 31 / 127, 93 -> 96\n",
      "#    Training the subspace: 32 / 127, 96 -> 99\n",
      "#    Training the subspace: 33 / 127, 99 -> 102\n",
      "#    Training the subspace: 34 / 127, 102 -> 105\n",
      "#    Training the subspace: 35 / 127, 105 -> 108\n",
      "#    Training the subspace: 36 / 127, 108 -> 111\n",
      "#    Training the subspace: 37 / 127, 111 -> 114\n",
      "#    Training the subspace: 38 / 127, 114 -> 117\n",
      "#    Training the subspace: 39 / 127, 117 -> 120\n",
      "#    Training the subspace: 40 / 127, 120 -> 123\n",
      "#    Training the subspace: 41 / 127, 123 -> 126\n",
      "#    Training the subspace: 42 / 127, 126 -> 129\n",
      "#    Training the subspace: 43 / 127, 129 -> 132\n",
      "#    Training the subspace: 44 / 127, 132 -> 135\n",
      "#    Training the subspace: 45 / 127, 135 -> 138\n",
      "#    Training the subspace: 46 / 127, 138 -> 140\n",
      "#    Training the subspace: 47 / 127, 140 -> 142\n",
      "#    Training the subspace: 48 / 127, 142 -> 144\n",
      "#    Training the subspace: 49 / 127, 144 -> 146\n",
      "#    Training the subspace: 50 / 127, 146 -> 148\n",
      "#    Training the subspace: 51 / 127, 148 -> 150\n",
      "#    Training the subspace: 52 / 127, 150 -> 152\n",
      "#    Training the subspace: 53 / 127, 152 -> 154\n",
      "#    Training the subspace: 54 / 127, 154 -> 156\n",
      "#    Training the subspace: 55 / 127, 156 -> 158\n",
      "#    Training the subspace: 56 / 127, 158 -> 160\n",
      "#    Training the subspace: 57 / 127, 160 -> 162\n",
      "#    Training the subspace: 58 / 127, 162 -> 164\n",
      "#    Training the subspace: 59 / 127, 164 -> 166\n",
      "#    Training the subspace: 60 / 127, 166 -> 168\n",
      "#    Training the subspace: 61 / 127, 168 -> 170\n",
      "#    Training the subspace: 62 / 127, 170 -> 172\n",
      "#    Training the subspace: 63 / 127, 172 -> 174\n",
      "#    Training the subspace: 64 / 127, 174 -> 176\n",
      "#    Training the subspace: 65 / 127, 176 -> 178\n",
      "#    Training the subspace: 66 / 127, 178 -> 180\n",
      "#    Training the subspace: 67 / 127, 180 -> 182\n",
      "#    Training the subspace: 68 / 127, 182 -> 184\n",
      "#    Training the subspace: 69 / 127, 184 -> 186\n",
      "#    Training the subspace: 70 / 127, 186 -> 188\n",
      "#    Training the subspace: 71 / 127, 188 -> 190\n",
      "#    Training the subspace: 72 / 127, 190 -> 192\n",
      "#    Training the subspace: 73 / 127, 192 -> 194\n",
      "#    Training the subspace: 74 / 127, 194 -> 196\n",
      "#    Training the subspace: 75 / 127, 196 -> 198\n",
      "#    Training the subspace: 76 / 127, 198 -> 200\n",
      "#    Training the subspace: 77 / 127, 200 -> 202\n",
      "#    Training the subspace: 78 / 127, 202 -> 204\n",
      "#    Training the subspace: 79 / 127, 204 -> 206\n",
      "#    Training the subspace: 80 / 127, 206 -> 208\n",
      "#    Training the subspace: 81 / 127, 208 -> 210\n",
      "#    Training the subspace: 82 / 127, 210 -> 212\n",
      "#    Training the subspace: 83 / 127, 212 -> 214\n",
      "#    Training the subspace: 84 / 127, 214 -> 216\n",
      "#    Training the subspace: 85 / 127, 216 -> 218\n",
      "#    Training the subspace: 86 / 127, 218 -> 220\n",
      "#    Training the subspace: 87 / 127, 220 -> 222\n",
      "#    Training the subspace: 88 / 127, 222 -> 224\n",
      "#    Training the subspace: 89 / 127, 224 -> 226\n",
      "#    Training the subspace: 90 / 127, 226 -> 228\n",
      "#    Training the subspace: 91 / 127, 228 -> 230\n",
      "#    Training the subspace: 92 / 127, 230 -> 232\n",
      "#    Training the subspace: 93 / 127, 232 -> 234\n",
      "#    Training the subspace: 94 / 127, 234 -> 236\n",
      "#    Training the subspace: 95 / 127, 236 -> 238\n",
      "#    Training the subspace: 96 / 127, 238 -> 240\n",
      "#    Training the subspace: 97 / 127, 240 -> 242\n",
      "#    Training the subspace: 98 / 127, 242 -> 244\n",
      "#    Training the subspace: 99 / 127, 244 -> 246\n",
      "#    Training the subspace: 100 / 127, 246 -> 248\n",
      "#    Training the subspace: 101 / 127, 248 -> 250\n",
      "#    Training the subspace: 102 / 127, 250 -> 252\n",
      "#    Training the subspace: 103 / 127, 252 -> 254\n",
      "#    Training the subspace: 104 / 127, 254 -> 256\n",
      "#    Training the subspace: 105 / 127, 256 -> 258\n",
      "#    Training the subspace: 106 / 127, 258 -> 260\n",
      "#    Training the subspace: 107 / 127, 260 -> 262\n",
      "#    Training the subspace: 108 / 127, 262 -> 264\n",
      "#    Training the subspace: 109 / 127, 264 -> 266\n",
      "#    Training the subspace: 110 / 127, 266 -> 268\n",
      "#    Training the subspace: 111 / 127, 268 -> 270\n",
      "#    Training the subspace: 112 / 127, 270 -> 272\n",
      "#    Training the subspace: 113 / 127, 272 -> 274\n",
      "#    Training the subspace: 114 / 127, 274 -> 276\n",
      "#    Training the subspace: 115 / 127, 276 -> 278\n",
      "#    Training the subspace: 116 / 127, 278 -> 280\n",
      "#    Training the subspace: 117 / 127, 280 -> 282\n",
      "#    Training the subspace: 118 / 127, 282 -> 284\n",
      "#    Training the subspace: 119 / 127, 284 -> 286\n",
      "#    Training the subspace: 120 / 127, 286 -> 288\n",
      "#    Training the subspace: 121 / 127, 288 -> 290\n",
      "#    Training the subspace: 122 / 127, 290 -> 292\n",
      "#    Training the subspace: 123 / 127, 292 -> 294\n",
      "#    Training the subspace: 124 / 127, 294 -> 296\n",
      "#    Training the subspace: 125 / 127, 296 -> 298\n",
      "#    Training the subspace: 126 / 127, 298 -> 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8047048 1.9723519 2.0720026 ... 1.7036722 2.0171213 2.4082482]\n",
      "# compress items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.33it/s]\n",
      " 16%|████████████▊                                                                   | 32/200 [00:00<00:00, 316.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sorting items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 279.34it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 330.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 321.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 285.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 228.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# searching!\n",
      "expected items, overall time, avg recall, avg precision, avg error, avg items\n",
      "1, 0, 0.0, 0.0, 0, 1\n",
      "2, 0, 0.0, 0.0, 0, 2\n",
      "4, 0, 5e-05, 0.00025, 0, 4\n",
      "8, 0, 5e-05, 0.000125, 0, 8\n",
      "16, 0, 0.00015000000000000001, 0.0001875, 0, 16\n",
      "32, 0, 0.0003, 0.00018749999999999998, 0, 32\n",
      "64, 0, 0.0010999999999999998, 0.00034375, 0, 64\n",
      "128, 0, 0.0036, 0.0005625, 0, 128\n",
      "256, 0, 0.0094, 0.000734375, 0, 256\n",
      "512, 0, 0.0235, 0.00091796875, 0, 512\n",
      "1024, 0, 0.05765, 0.0011259765625, 0, 1024\n",
      "2048, 0, 0.117, 0.0011425781250000001, 0, 2048\n",
      "4096, 0, 0.23570000000000002, 0.00115087890625, 0, 4096\n",
      "8192, 0, 0.4855, 0.0011853027343749999, 0, 8192\n",
      "16384, 0, 0.9414, 0.001149169921875, 0, 16384\n",
      "32768, 0, 1.0, 0.0006103515625, 0, 32768\n",
      "--- 19.767059803009033 seconds ---, iteration 9\n",
      "# ranking metric product\n",
      "# NormPQ, percentiles: 100, quantize: Subspace PQ, M: 127, Ks : 100, code_dtype: <class 'numpy.uint8'>\n",
      "#    Training the subspace: 0 / 127, 0 -> 3\n",
      "#    Training the subspace: 1 / 127, 3 -> 6\n",
      "#    Training the subspace: 2 / 127, 6 -> 9\n",
      "#    Training the subspace: 3 / 127, 9 -> 12\n",
      "#    Training the subspace: 4 / 127, 12 -> 15\n",
      "#    Training the subspace: 5 / 127, 15 -> 18\n",
      "#    Training the subspace: 6 / 127, 18 -> 21\n",
      "#    Training the subspace: 7 / 127, 21 -> 24\n",
      "#    Training the subspace: 8 / 127, 24 -> 27\n",
      "#    Training the subspace: 9 / 127, 27 -> 30\n",
      "#    Training the subspace: 10 / 127, 30 -> 33\n",
      "#    Training the subspace: 11 / 127, 33 -> 36\n",
      "#    Training the subspace: 12 / 127, 36 -> 39\n",
      "#    Training the subspace: 13 / 127, 39 -> 42\n",
      "#    Training the subspace: 14 / 127, 42 -> 45\n",
      "#    Training the subspace: 15 / 127, 45 -> 48\n",
      "#    Training the subspace: 16 / 127, 48 -> 51\n",
      "#    Training the subspace: 17 / 127, 51 -> 54\n",
      "#    Training the subspace: 18 / 127, 54 -> 57\n",
      "#    Training the subspace: 19 / 127, 57 -> 60\n",
      "#    Training the subspace: 20 / 127, 60 -> 63\n",
      "#    Training the subspace: 21 / 127, 63 -> 66\n",
      "#    Training the subspace: 22 / 127, 66 -> 69\n",
      "#    Training the subspace: 23 / 127, 69 -> 72\n",
      "#    Training the subspace: 24 / 127, 72 -> 75\n",
      "#    Training the subspace: 25 / 127, 75 -> 78\n",
      "#    Training the subspace: 26 / 127, 78 -> 81\n",
      "#    Training the subspace: 27 / 127, 81 -> 84\n",
      "#    Training the subspace: 28 / 127, 84 -> 87\n",
      "#    Training the subspace: 29 / 127, 87 -> 90\n",
      "#    Training the subspace: 30 / 127, 90 -> 93\n",
      "#    Training the subspace: 31 / 127, 93 -> 96\n",
      "#    Training the subspace: 32 / 127, 96 -> 99\n",
      "#    Training the subspace: 33 / 127, 99 -> 102\n",
      "#    Training the subspace: 34 / 127, 102 -> 105\n",
      "#    Training the subspace: 35 / 127, 105 -> 108\n",
      "#    Training the subspace: 36 / 127, 108 -> 111\n",
      "#    Training the subspace: 37 / 127, 111 -> 114\n",
      "#    Training the subspace: 38 / 127, 114 -> 117\n",
      "#    Training the subspace: 39 / 127, 117 -> 120\n",
      "#    Training the subspace: 40 / 127, 120 -> 123\n",
      "#    Training the subspace: 41 / 127, 123 -> 126\n",
      "#    Training the subspace: 42 / 127, 126 -> 129\n",
      "#    Training the subspace: 43 / 127, 129 -> 132\n",
      "#    Training the subspace: 44 / 127, 132 -> 135\n",
      "#    Training the subspace: 45 / 127, 135 -> 138\n",
      "#    Training the subspace: 46 / 127, 138 -> 140\n",
      "#    Training the subspace: 47 / 127, 140 -> 142\n",
      "#    Training the subspace: 48 / 127, 142 -> 144\n",
      "#    Training the subspace: 49 / 127, 144 -> 146\n",
      "#    Training the subspace: 50 / 127, 146 -> 148\n",
      "#    Training the subspace: 51 / 127, 148 -> 150\n",
      "#    Training the subspace: 52 / 127, 150 -> 152\n",
      "#    Training the subspace: 53 / 127, 152 -> 154\n",
      "#    Training the subspace: 54 / 127, 154 -> 156\n",
      "#    Training the subspace: 55 / 127, 156 -> 158\n",
      "#    Training the subspace: 56 / 127, 158 -> 160\n",
      "#    Training the subspace: 57 / 127, 160 -> 162\n",
      "#    Training the subspace: 58 / 127, 162 -> 164\n",
      "#    Training the subspace: 59 / 127, 164 -> 166\n",
      "#    Training the subspace: 60 / 127, 166 -> 168\n",
      "#    Training the subspace: 61 / 127, 168 -> 170\n",
      "#    Training the subspace: 62 / 127, 170 -> 172\n",
      "#    Training the subspace: 63 / 127, 172 -> 174\n",
      "#    Training the subspace: 64 / 127, 174 -> 176\n",
      "#    Training the subspace: 65 / 127, 176 -> 178\n",
      "#    Training the subspace: 66 / 127, 178 -> 180\n",
      "#    Training the subspace: 67 / 127, 180 -> 182\n",
      "#    Training the subspace: 68 / 127, 182 -> 184\n",
      "#    Training the subspace: 69 / 127, 184 -> 186\n",
      "#    Training the subspace: 70 / 127, 186 -> 188\n",
      "#    Training the subspace: 71 / 127, 188 -> 190\n",
      "#    Training the subspace: 72 / 127, 190 -> 192\n",
      "#    Training the subspace: 73 / 127, 192 -> 194\n",
      "#    Training the subspace: 74 / 127, 194 -> 196\n",
      "#    Training the subspace: 75 / 127, 196 -> 198\n",
      "#    Training the subspace: 76 / 127, 198 -> 200\n",
      "#    Training the subspace: 77 / 127, 200 -> 202\n",
      "#    Training the subspace: 78 / 127, 202 -> 204\n",
      "#    Training the subspace: 79 / 127, 204 -> 206\n",
      "#    Training the subspace: 80 / 127, 206 -> 208\n",
      "#    Training the subspace: 81 / 127, 208 -> 210\n",
      "#    Training the subspace: 82 / 127, 210 -> 212\n",
      "#    Training the subspace: 83 / 127, 212 -> 214\n",
      "#    Training the subspace: 84 / 127, 214 -> 216\n",
      "#    Training the subspace: 85 / 127, 216 -> 218\n",
      "#    Training the subspace: 86 / 127, 218 -> 220\n",
      "#    Training the subspace: 87 / 127, 220 -> 222\n",
      "#    Training the subspace: 88 / 127, 222 -> 224\n",
      "#    Training the subspace: 89 / 127, 224 -> 226\n",
      "#    Training the subspace: 90 / 127, 226 -> 228\n",
      "#    Training the subspace: 91 / 127, 228 -> 230\n",
      "#    Training the subspace: 92 / 127, 230 -> 232\n",
      "#    Training the subspace: 93 / 127, 232 -> 234\n",
      "#    Training the subspace: 94 / 127, 234 -> 236\n",
      "#    Training the subspace: 95 / 127, 236 -> 238\n",
      "#    Training the subspace: 96 / 127, 238 -> 240\n",
      "#    Training the subspace: 97 / 127, 240 -> 242\n",
      "#    Training the subspace: 98 / 127, 242 -> 244\n",
      "#    Training the subspace: 99 / 127, 244 -> 246\n",
      "#    Training the subspace: 100 / 127, 246 -> 248\n",
      "#    Training the subspace: 101 / 127, 248 -> 250\n",
      "#    Training the subspace: 102 / 127, 250 -> 252\n",
      "#    Training the subspace: 103 / 127, 252 -> 254\n",
      "#    Training the subspace: 104 / 127, 254 -> 256\n",
      "#    Training the subspace: 105 / 127, 256 -> 258\n",
      "#    Training the subspace: 106 / 127, 258 -> 260\n",
      "#    Training the subspace: 107 / 127, 260 -> 262\n",
      "#    Training the subspace: 108 / 127, 262 -> 264\n",
      "#    Training the subspace: 109 / 127, 264 -> 266\n",
      "#    Training the subspace: 110 / 127, 266 -> 268\n",
      "#    Training the subspace: 111 / 127, 268 -> 270\n",
      "#    Training the subspace: 112 / 127, 270 -> 272\n",
      "#    Training the subspace: 113 / 127, 272 -> 274\n",
      "#    Training the subspace: 114 / 127, 274 -> 276\n",
      "#    Training the subspace: 115 / 127, 276 -> 278\n",
      "#    Training the subspace: 116 / 127, 278 -> 280\n",
      "#    Training the subspace: 117 / 127, 280 -> 282\n",
      "#    Training the subspace: 118 / 127, 282 -> 284\n",
      "#    Training the subspace: 119 / 127, 284 -> 286\n",
      "#    Training the subspace: 120 / 127, 286 -> 288\n",
      "#    Training the subspace: 121 / 127, 288 -> 290\n",
      "#    Training the subspace: 122 / 127, 290 -> 292\n",
      "#    Training the subspace: 123 / 127, 292 -> 294\n",
      "#    Training the subspace: 124 / 127, 294 -> 296\n",
      "#    Training the subspace: 125 / 127, 296 -> 298\n",
      "#    Training the subspace: 126 / 127, 298 -> 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.139832  1.8130808 1.9505788 ... 1.641113  1.7342975 1.6828322]\n",
      "# compress items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.02it/s]\n",
      " 14%|███████████▌                                                                    | 29/200 [00:00<00:00, 278.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sorting items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 290.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 268.10it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 309.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 335.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 200/200 [00:00<00:00, 302.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# searching!\n",
      "expected items, overall time, avg recall, avg precision, avg error, avg items\n",
      "1, 0, 0.0, 0.0, 0, 1\n",
      "2, 0, 0.0, 0.0, 0, 2\n",
      "4, 0, 0.0001, 0.0005, 0, 4\n",
      "8, 0, 0.00015000000000000001, 0.000375, 0, 8\n",
      "16, 0, 0.0002, 0.00025, 0, 16\n",
      "32, 0, 0.00055, 0.00034375000000000003, 0, 32\n",
      "64, 0, 0.00175, 0.000546875, 0, 64\n",
      "128, 0, 0.0078000000000000005, 0.00121875, 0, 128\n",
      "256, 0, 0.019600000000000003, 0.0015312500000000003, 0, 256\n",
      "512, 0, 0.0342, 0.0013359375, 0, 512\n",
      "1024, 0, 0.05275, 0.0010302734375, 0, 1024\n",
      "2048, 0, 0.10175, 0.0009936523437499999, 0, 2048\n",
      "4096, 0, 0.23779999999999998, 0.0011611328124999998, 0, 4096\n",
      "8192, 0, 0.45874999999999994, 0.0011199951171874999, 0, 8192\n",
      "16384, 0, 0.9011999999999999, 0.0011000976562499998, 0, 16384\n",
      "32768, 0, 1.0, 0.0006103515625, 0, 32768\n",
      "--- 22.242144107818604 seconds ---, iteration 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    ks = [32, 32, 100, 100]\n",
    "    cs = [8, 16, 32, 128]\n",
    "    pi = 3\n",
    "    dataset = 'netflix'\n",
    "    topk = 20\n",
    "    codebook = cs[pi]\n",
    "    Ks = ks[pi]\n",
    "    metric = 'product'\n",
    "\n",
    "    # override default parameters with command line parameters\n",
    "    import sys\n",
    "    if len(sys.argv) > 3:\n",
    "        dataset, topk, codebook, Ks, metric = parse_args()\n",
    "    else:\n",
    "        import warnings\n",
    "        warnings.warn(\"Using  Default Parameters \")\n",
    "    print(\"# Parameters: dataset = {}, topK = {}, codebook = {}, Ks = {}, metric = {}\"\n",
    "          .format(dataset, topk, codebook, Ks, metric))\n",
    "\n",
    "\n",
    "    X, T, Q, G = loader(dataset, topk, metric, folder='data/')\n",
    "    # pq, rq, or component of norm-pq\n",
    "    recall_item_curve = np.zeros((10,16))\n",
    "    time_list = []\n",
    "    for i in range(0,10):\n",
    "        quantizer = NormPQ(n_percentile=Ks, quantize=PQ(M=codebook-1, Ks=Ks), method='kmeans')\n",
    "        start_time = time.time()\n",
    "        recall_item_curve[i,:], recalls = execute(quantizer,  X, T, Q, G, metric)\n",
    "        print(\"--- %s seconds ---, iteration %s\" % (time.time() - start_time,i+1))\n",
    "        time_list.append(time.time() - start_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa723bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "14915b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [512, 1024, 2048, 4096, 8192, 16384]\n",
    "firstit = recall_item_curve[1,:]\n",
    "fifthit = recall_item_curve[5,:]\n",
    "tenthit = recall_item_curve[9,:]\n",
    "recall_Set.append(recall_item_curve[:,11:15])\n",
    "recall_average = recall_item_curve.mean(axis=0)\n",
    "plt.rc('axes', titlesize=25, labelsize = 15)\n",
    "plt.rc('xtick', labelsize=15)\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "plt.plot(x,firstit[9:15], 'co--',label='1st iteration')\n",
    "plt.plot(x,fifthit[9:15], 'go--',label = '5th iteration')\n",
    "plt.plot(x,tenthit[9:15], 'bo--',label = '10th iteration')\n",
    "plt.plot(x, recall_average[9:15], 'r', label = 'Average Recall')\n",
    "plt.xlabel('Number of Items')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.grid(\"True\")\n",
    "plt.title(\"Setting#%s: (#Codebooks = %s, #Clusters = %s)\" % (pi+1, cs[pi], ks[pi]))\n",
    "plt.savefig(\"setting%s.png\" % (pi+1),dpi=900)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "4224b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_time[pi] = round((np.mean(time_list)),2)\n",
    "average_std[pi] = round((recall_item_curve.std()),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "111d9524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.6, 7.76, 11.67, 18.13]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "7f5f27eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32, 0.32, 0.32, 0.32]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "683a9fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.110935 0.23366  0.473895 0.916175]\n",
      " [0.10823  0.232615 0.472625 0.91457 ]\n",
      " [0.110735 0.230855 0.47113  0.916815]\n",
      " [0.11213  0.231655 0.46713  0.919165]]\n"
     ]
    }
   ],
   "source": [
    "recall_numbers = np.array(recall_Set)\n",
    "print(recall_numbers.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c075cfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf=[0.118, 0.234, 0.468, 0.931]\n",
    "r = [0.110, 0.220, 0.450, 0.904]\n",
    "plt.style.use('ggplot')\n",
    "index = np.arange(4)\n",
    "bar_width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fuzzy_norm = ax.bar(index, rf, bar_width,\n",
    "                label=\"Fuzzy Norm-Explicit PQ\")\n",
    "\n",
    "norm = ax.bar(index+bar_width, r,\n",
    "                 bar_width, label=\"Norm-Explicit PQ\")\n",
    "\n",
    "ax.set_xlabel('#Items')\n",
    "ax.set_ylabel('Recall')\n",
    "ax.set_title('Comparison Bar Plot of Methods')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels([2048, 4096, 8192, 16384])\n",
    "ax.legend()\n",
    "plt.savefig('comparison_barplot.png', dpi=900)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43f6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
